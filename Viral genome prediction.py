# -*- coding: utf-8 -*-
"""Untitled6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1K8aYujvWXqT6Mutd3N3Durum82ob3ypT
"""





# Install packages
!pip install -q scikit-learn matplotlib seaborn

import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    matthews_corrcoef, cohen_kappa_score, confusion_matrix,
    classification_report, roc_curve, auc, precision_recall_curve
)
from sklearn.utils import resample
import matplotlib.pyplot as plt
import seaborn as sns

# Set seed
np.random.seed(42)

# Load dataset
df = pd.read_csv("merge-csv.com__683fc98d75a00.csv", names=["id", "sequence", "label"], skiprows=1)
df.dropna(subset=["sequence", "label"], inplace=True)
df["label"] = pd.to_numeric(df["label"], errors='coerce')
df.dropna(subset=["label"], inplace=True)
df["label"] = df["label"].astype(int)
df["sequence"] = df["sequence"].str.lower()
df = df[df["sequence"].str.len() >= 6]

# Generate k-mers
def get_kmers(seq, k=6):
    return " ".join([seq[i:i+k] for i in range(len(seq)-k+1)])
df["kmers"] = df["sequence"].apply(get_kmers)
print(df["kmers"])
from sklearn.feature_extraction.text import CountVectorizer

# Balance dataset via upsampling
df_major = df[df["label"] == 0]
df_minor = df[df["label"] == 1]
df_minor_upsampled = resample(df_minor, replace=True, n_samples=len(df_major), random_state=42)
df_balanced = pd.concat([df_major, df_minor_upsampled]).sample(frac=1, random_state=42)

# TF-IDF Vectorization
vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(4, 6), max_features=20000)
X = vectorizer.fit_transform(df_balanced["kmers"])
y = df_balanced["label"].values

# Use CountVectorizer with same settings as TfidfVectorizer
count_vectorizer = CountVectorizer(analyzer='word', ngram_range=(4, 6), max_features=20000)

# Fit and transform the data
X_counts = count_vectorizer.fit_transform(df_balanced["kmers"])

# Get feature names (k-mers)
feature_names = count_vectorizer.get_feature_names_out()

# Sum up counts of each k-mer across all samples
kmer_counts = X_counts.sum(axis=0).A1  # .A1 converts sparse matrix to flat array

# Combine feature names and counts
kmer_freq = list(zip(feature_names, kmer_counts))

# Sort by frequency in descending order
sorted_kmers = sorted(kmer_freq, key=lambda x: x[1], reverse=True)

# Print top 20 most frequent k-mers
print("Top 20 most frequent k-mers by count:")
for kmer, count in sorted_kmers[:200]:
    print(f"{kmer}: Count = {count}")


# Split
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)

# Train KNN
knn = KNeighborsClassifier(n_neighbors=1, weights='distance', metric='cosine')
knn.fit(X_train, y_train)
y_pred = knn.predict(X_test)

# Evaluation
print(" Accuracy:", round(accuracy_score(y_test, y_pred), 4))
print("\n", classification_report(y_test, y_pred, digits=4))

# Normalized confusion matrix
cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
plt.figure(figsize=(6, 5))
sns.heatmap(cm_norm, annot=True, fmt=".2f", cmap="Greens", cbar=False,
            xticklabels=["Pred 0", "Pred 1"],
            yticklabels=["Actual 0", "Actual 1"])
plt.title("Normalized Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.show()
plt.savefig("normalized_confusion_matrix.png", dpi=300)

# ROC Curve
y_prob = knn.predict_proba(X_test)[:, 1]
fpr, tpr, _ = roc_curve(y_test, y_prob)
roc_auc = auc(fpr, tpr)
plt.figure()
plt.plot(fpr, tpr, color='darkorange', label=f"ROC curve (AUC = {roc_auc:.2f})")
plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
plt.title("ROC Curve")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend()
plt.tight_layout()
plt.show()
plt.savefig("roc_curve.png", dpi=300)

# Precision-Recall Curve
precision, recall, _ = precision_recall_curve(y_test, y_prob)
plt.figure()
plt.plot(recall, precision, color="purple")
plt.title("Precision-Recall Curve")
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.tight_layout()
plt.show()
plt.savefig("precision_recall_curve.png", dpi=300)



# Install packages
!pip install -q scikit-learn matplotlib seaborn

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.utils import resample
from sklearn.metrics import (
    accuracy_score, classification_report, confusion_matrix,
    roc_curve, auc, precision_recall_curve, f1_score
)

# Set seed
np.random.seed(42)

# Load dataset
df = pd.read_csv("merge-csv.com__683fc98d75a00.csv", names=["id", "sequence", "label"], skiprows=1)
df.dropna(subset=["sequence", "label"], inplace=True)
df["label"] = pd.to_numeric(df["label"], errors='coerce')
df.dropna(subset=["label"], inplace=True)
df["label"] = df["label"].astype(int)
df["sequence"] = df["sequence"].str.lower()
df = df[df["sequence"].str.len() >= 6]

# Generate k-mers
def get_kmers(seq, k=6):
    return " ".join([seq[i:i+k] for i in range(len(seq)-k+1)])
df["kmers"] = df["sequence"].apply(get_kmers)

# Balance dataset via upsampling
df_major = df[df["label"] == 0]
df_minor = df[df["label"] == 1]
df_minor_upsampled = resample(df_minor, replace=True, n_samples=len(df_major), random_state=42)
df_balanced = pd.concat([df_major, df_minor_upsampled]).sample(frac=1, random_state=42)

# TF-IDF Vectorization (reduce max_features to control memory)
vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(4, 6), max_features=10000)
X = vectorizer.fit_transform(df_balanced["kmers"])
y = df_balanced["label"].values

# Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)

# Train SVM with probability=True for ROC/PR curves
model = SVC(kernel='linear', probability=True, random_state=42)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
y_probs = model.predict_proba(X_test)[:, 1]

# Evaluation
print("SVM Accuracy:", round(accuracy_score(y_test, y_pred), 4))
print("\nClassification Report:\n", classification_report(y_test, y_pred, digits=4))

# Normalized Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
plt.figure(figsize=(6, 5))
sns.heatmap(cm_norm, annot=True, fmt=".2f", cmap="Greens", cbar=False,
            xticklabels=["Pred 0", "Pred 1"], yticklabels=["Actual 0", "Actual 1"])
plt.title("Normalized Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.savefig("normalized_confusion_matrix.png", dpi=300)
plt.show()

# ROC Curve
fpr, tpr, _ = roc_curve(y_test, y_probs)
roc_auc = auc(fpr, tpr)
plt.figure(figsize=(6, 5))
plt.plot(fpr, tpr, color='darkorange', label=f"ROC curve (AUC = {roc_auc:.4f})")
plt.plot([0, 1], [0, 1], linestyle='--', color='navy')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve - SVM")
plt.legend()
plt.tight_layout()
plt.savefig("roc_curve.png", dpi=300)
plt.show()

# Precision-Recall Curve
precision, recall, _ = precision_recall_curve(y_test, y_probs)
plt.figure(figsize=(6, 5))
plt.plot(recall, precision, color="purple")
plt.title("Precision-Recall Curve")
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.tight_layout()
plt.savefig("precision_recall_curve.png", dpi=300)
plt.show()

# Install necessary packages
!pip install -q scikit-learn matplotlib seaborn lightgbm

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from lightgbm import LGBMClassifier
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    classification_report, confusion_matrix, roc_curve, auc, precision_recall_curve
)
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.utils import resample

# Load dataset
df = pd.read_csv("merge-csv.com__683fc98d75a00.csv", names=["id", "sequence", "label"], skiprows=1)
df.dropna(subset=["sequence", "label"], inplace=True)
df["label"] = pd.to_numeric(df["label"], errors='coerce')
df.dropna(subset=["label"], inplace=True)
df["label"] = df["label"].astype(int)
df["sequence"] = df["sequence"].str.lower()
df = df[df["sequence"].str.len() >= 6]

# K-mer function
def get_kmers(seq, k=6):
    return " ".join([seq[i:i+k] for i in range(len(seq) - k + 1)])

df["kmers"] = df["sequence"].apply(get_kmers)

# Balance dataset via upsampling
df_major = df[df["label"] == 0]
df_minor = df[df["label"] == 1]
df_minor_upsampled = resample(df_minor, replace=True, n_samples=len(df_major), random_state=42)
df_balanced = pd.concat([df_major, df_minor_upsampled]).sample(frac=1, random_state=42)

# TF-IDF Vectorization
vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(4, 6), max_features=20000)
X = vectorizer.fit_transform(df_balanced["kmers"])
y = df_balanced["label"].values

# Split the data
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)

# Train LightGBM
model = LGBMClassifier(
    num_leaves=64,
    max_depth=7,
    learning_rate=0.05,
    n_estimators=300,
    class_weight='balanced',
    random_state=42
)
model.fit(X_train, y_train)

# Threshold tuning on validation set
val_probs = model.predict_proba(X_val)[:, 1]
best_thresh, best_f1 = 0.5, 0
for t in np.arange(0.1, 0.9, 0.01):
    preds = (val_probs >= t).astype(int)
    f1 = f1_score(y_val, preds)
    if f1 > best_f1:
        best_thresh, best_f1 = t, f1

# Final predictions on test set
test_probs = model.predict_proba(X_test)[:, 1]
test_pred = (test_probs >= best_thresh).astype(int)

# Evaluation
print(f"\nBest Threshold: {best_thresh:.2f}")
print("Tuned LightGBM Accuracy:", round(accuracy_score(y_test, test_pred), 4))
print("\nClassification Report:\n", classification_report(y_test, test_pred, digits=4))

# Normalized Confusion Matrix
cm = confusion_matrix(y_test, test_pred)
cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
plt.figure(figsize=(6, 5))
sns.heatmap(cm_norm, annot=True, fmt=".2f", cmap="Greens", cbar=False,
            xticklabels=["Pred 0", "Pred 1"], yticklabels=["Actual 0", "Actual 1"])
plt.title("Normalized Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.savefig("normalized_confusion_matrix.png", dpi=300)
plt.show()

# ROC Curve
fpr, tpr, _ = roc_curve(y_test, test_probs)
roc_auc = auc(fpr, tpr)
plt.figure(figsize=(6, 5))
plt.plot(fpr, tpr, color='darkorange', label=f"ROC curve (AUC = {roc_auc:.4f})")
plt.plot([0, 1], [0, 1], linestyle='--', color='navy')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve - LightGBM")
plt.legend()
plt.tight_layout()
plt.savefig("roc_curve.png", dpi=300)
plt.show()

# Precision-Recall Curve
precision, recall, _ = precision_recall_curve(y_test, test_probs)
plt.figure(figsize=(6, 5))
plt.plot(recall, precision, color="purple")
plt.title("Precision-Recall Curve")
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.tight_layout()
plt.savefig("precision_recall_curve.png", dpi=300)
plt.show()

# Install packages
!pip install -q scikit-learn matplotlib seaborn

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.utils import resample
from sklearn.metrics import (
    accuracy_score, classification_report, confusion_matrix,
    roc_curve, auc, precision_recall_curve, f1_score
)

# Set seed
np.random.seed(42)

# Load dataset
df = pd.read_csv("merge-csv.com__683fc98d75a00.csv", names=["id", "sequence", "label"], skiprows=1)
df.dropna(subset=["sequence", "label"], inplace=True)
df["label"] = pd.to_numeric(df["label"], errors='coerce')
df.dropna(subset=["label"], inplace=True)
df["label"] = df["label"].astype(int)
df["sequence"] = df["sequence"].str.lower()
df = df[df["sequence"].str.len() >= 6]

# Generate k-mers
def get_kmers(seq, k=6):
    return " ".join([seq[i:i+k] for i in range(len(seq)-k+1)])
df["kmers"] = df["sequence"].apply(get_kmers)

# Balance dataset via upsampling
df_major = df[df["label"] == 0]
df_minor = df[df["label"] == 1]
df_minor_upsampled = resample(df_minor, replace=True, n_samples=len(df_major), random_state=42)
df_balanced = pd.concat([df_major, df_minor_upsampled]).sample(frac=1, random_state=42)

# TF-IDF Vectorization
vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(4, 6), max_features=20000)
X = vectorizer.fit_transform(df_balanced["kmers"])
y = df_balanced["label"].values

# Split into train/test
# Split into train/test
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)

# Train Logistic Regression
model = LogisticRegression(max_iter=2000, random_state=42)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
y_probs = model.predict_proba(X_test)[:, 1]

# Evaluation
print("Accuracy:", round(accuracy_score(y_test, y_pred), 4))
print("\nClassification Report:\n", classification_report(y_test, y_pred, digits=4))

# Normalized Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
plt.figure(figsize=(6, 5))
sns.heatmap(cm_norm, annot=True, fmt=".2f", cmap="Greens", cbar=False,
            xticklabels=["Pred 0", "Pred 1"], yticklabels=["Actual 0", "Actual 1"])
plt.title("Normalized Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.savefig("normalized_confusion_matrix.png", dpi=300)
plt.show()

# ROC Curve
fpr, tpr, _ = roc_curve(y_test, y_probs)
roc_auc = auc(fpr, tpr)
plt.figure(figsize=(6, 5))
plt.plot(fpr, tpr, color='darkorange', label=f"ROC curve (AUC = {roc_auc:.4f})")
plt.plot([0, 1], [0, 1], linestyle='--', color='navy')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve - Logistic Regression")
plt.legend()
plt.tight_layout()
plt.savefig("roc_curve.png", dpi=300)
plt.show()

# Precision-Recall Curve
precision, recall, _ = precision_recall_curve(y_test, y_probs)
plt.figure(figsize=(6, 5))
plt.plot(recall, precision, color="purple")
plt.title("Precision-Recall Curve")
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.tight_layout()
plt.savefig("precision_recall_curve.png", dpi=300)
plt.show()

# Install packages (if needed)
!pip install -q scikit-learn matplotlib seaborn

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import (
    accuracy_score, classification_report, confusion_matrix,
    f1_score, roc_curve, auc, precision_recall_curve
)
from sklearn.utils import resample

# Load dataset
df = pd.read_csv(
    "/content/merge-csv.com__683fc98d75a00.csv",
    names=["id", "sequence", "label"],
    skiprows=1,
    dtype={"id": str, "sequence": str, "label": str},
    low_memory=False
)

# Preprocess
df.dropna(subset=["sequence", "label"], inplace=True)
df = df[df["label"].str.isnumeric()]
df["label"] = df["label"].astype(int)
df["sequence"] = df["sequence"].str.lower()
df = df[df["sequence"].str.len() >= 6]

# K-mer function
def get_kmers(seq, k=6):
    return " ".join([seq[i:i+k] for i in range(len(seq) - k + 1)])

df["kmers"] = df["sequence"].apply(get_kmers)

# Balance dataset via upsampling
df_major = df[df["label"] == 0]
df_minor = df[df["label"] == 1]
df_minor_upsampled = resample(df_minor, replace=True, n_samples=len(df_major), random_state=42)
df_balanced = pd.concat([df_major, df_minor_upsampled]).sample(frac=1, random_state=42)

# TF-IDF Vectorization
vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(4, 6), max_features=20000)
X = vectorizer.fit_transform(df_balanced["kmers"])
y = df_balanced["label"].values

# Split into train/test (80/20)
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)

# Train Gradient Boosting Classifier
model = GradientBoostingClassifier(
    n_estimators=300,
    learning_rate=0.05,
    max_depth=6,
    random_state=42
)
model.fit(X_train, y_train)

# Predict
y_probs = model.predict_proba(X_test)[:, 1]
y_pred = (y_probs >= 0.5).astype(int)  # default threshold = 0.5

# Evaluation
print("GradientBoostingClassifier Accuracy:", round(accuracy_score(y_test, y_pred), 4))
print("\nClassification Report:\n", classification_report(y_test, y_pred, digits=4))

# Normalized Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
plt.figure(figsize=(6, 5))
sns.heatmap(cm_norm, annot=True, fmt=".2f", cmap="Greens", cbar=False,
            xticklabels=["Pred 0", "Pred 1"], yticklabels=["Actual 0", "Actual 1"])
plt.title("Normalized Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.savefig("normalized_confusion_matrix.png", dpi=300)
plt.show()

# ROC Curve
fpr, tpr, _ = roc_curve(y_test, y_probs)
roc_auc = auc(fpr, tpr)
plt.figure(figsize=(6, 5))
plt.plot(fpr, tpr, color='darkorange', label=f"ROC curve (AUC = {roc_auc:.4f})")
plt.plot([0, 1], [0, 1], linestyle='--', color='navy')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve - Gradient Boosting")
plt.legend()
plt.tight_layout()
plt.savefig("roc_curve.png", dpi=300)
plt.show()

# Precision-Recall Curve
precision, recall, _ = precision_recall_curve(y_test, y_probs)
plt.figure(figsize=(6, 5))
plt.plot(recall, precision, color="purple")
plt.title("Precision-Recall Curve")
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.tight_layout()
plt.savefig("precision_recall_curve.png", dpi=300)
plt.show()

# Install packages
!pip install -q scikit-learn matplotlib seaborn

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.ensemble import AdaBoostClassifier
from sklearn.utils import resample
from sklearn.metrics import (
    accuracy_score, classification_report, confusion_matrix,
    roc_curve, auc, precision_recall_curve, f1_score
)

# Set seed
np.random.seed(42)

# Load dataset
df = pd.read_csv("merge-csv.com__683fc98d75a00.csv", names=["id", "sequence", "label"], skiprows=1)
df.dropna(subset=["sequence", "label"], inplace=True)
df["label"] = pd.to_numeric(df["label"], errors='coerce')
df.dropna(subset=["label"], inplace=True)
df["label"] = df["label"].astype(int)
df["sequence"] = df["sequence"].str.lower()
df = df[df["sequence"].str.len() >= 6]

# Generate k-mers
def get_kmers(seq, k=6):
    return " ".join([seq[i:i+k] for i in range(len(seq)-k+1)])
df["kmers"] = df["sequence"].apply(get_kmers)

# Balance dataset via upsampling
df_major = df[df["label"] == 0]
df_minor = df[df["label"] == 1]
df_minor_upsampled = resample(df_minor, replace=True, n_samples=len(df_major), random_state=42)
df_balanced = pd.concat([df_major, df_minor_upsampled]).sample(frac=1, random_state=42)

# TF-IDF Vectorization (reduced features to prevent overload)
vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(4, 6), max_features=10000)
X = vectorizer.fit_transform(df_balanced["kmers"])
y = df_balanced["label"].values

# Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)

# Train AdaBoost Classifier
model = AdaBoostClassifier(
    n_estimators=200,
    learning_rate=0.1,
    random_state=42
)
model.fit(X_train, y_train)

# Predict
y_pred = model.predict(X_test)
y_probs = model.predict_proba(X_test)[:, 1]

# Evaluation
print("AdaBoostClassifier Accuracy:", round(accuracy_score(y_test, y_pred), 4))
print("\nClassification Report:\n", classification_report(y_test, y_pred, digits=4))

# Normalized Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
plt.figure(figsize=(6, 5))
sns.heatmap(cm_norm, annot=True, fmt=".2f", cmap="Greens", cbar=False,
            xticklabels=["Pred 0", "Pred 1"], yticklabels=["Actual 0", "Actual 1"])
plt.title("Normalized Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.savefig("normalized_confusion_matrix.png", dpi=300)
plt.show()

# ROC Curve
fpr, tpr, _ = roc_curve(y_test, y_probs)
roc_auc = auc(fpr, tpr)
plt.figure(figsize=(6, 5))
plt.plot(fpr, tpr, color='darkorange', label=f"ROC curve (AUC = {roc_auc:.4f})")
plt.plot([0, 1], [0, 1], linestyle='--', color='navy')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve - AdaBoostClassifier")
plt.legend()
plt.tight_layout()
plt.savefig("roc_curve.png", dpi=300)
plt.show()

# Precision-Recall Curve
precision, recall, _ = precision_recall_curve(y_test, y_probs)
plt.figure(figsize=(6, 5))
plt.plot(recall, precision, color="purple")
plt.title("Precision-Recall Curve")
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.tight_layout()
plt.savefig("precision_recall_curve.png", dpi=300)
plt.show()



# Install packages
!pip install -q scikit-learn imbalanced-learn matplotlib seaborn

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics import (
    accuracy_score, classification_report, confusion_matrix,
    roc_curve, auc, precision_recall_curve, f1_score
)
from imblearn.over_sampling import SMOTE
import matplotlib.pyplot as plt
import seaborn as sns

# Load and clean dataset
df = pd.read_csv("merge-csv.com__683fc98d75a00.csv", header=None)
df.columns = ["ID", "Sequence", "Label"]
df.dropna(subset=["Sequence", "Label"], inplace=True)
df["Label"] = pd.to_numeric(df["Label"], errors="coerce")
df.dropna(subset=["Label"], inplace=True)
df["Label"] = df["Label"].astype(int)

# K-mer conversion
def get_kmers(seq, k=4):
    return ' '.join([seq[i:i+k] for i in range(len(seq) - k + 1)])

df["kmers"] = df["Sequence"].str.upper().apply(lambda x: get_kmers(x, k=4))

# Vectorization (limit features to reduce noise)
vectorizer = CountVectorizer(max_features=8000)
X = vectorizer.fit_transform(df["kmers"])
y = df["Label"]

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)

# Apply SMOTE to training data
smote = SMOTE(random_state=42)
X_train_bal, y_train_bal = smote.fit_resample(X_train, y_train)

# Convert to dense for Linear Regression
X_train_bal = X_train_bal.toarray()
X_test_dense = X_test.toarray()

# Train Linear Regression
model = LinearRegression()
model.fit(X_train_bal, y_train_bal)

# Predict probabilities
y_pred_cont = model.predict(X_test_dense)

# Threshold tuning to improve F1/recall
best_thresh = 0.5
best_f1 = 0
for t in np.arange(0.1, 0.9, 0.01):
    preds = (y_pred_cont >= t).astype(int)
    score = f1_score(y_test, preds)
    if score > best_f1:
        best_thresh = t
        best_f1 = score

# Final predictions
y_pred = (y_pred_cont >= best_thresh).astype(int)

# Evaluation
print(f"Best threshold: {best_thresh:.2f}")
print(f"Linear Regression Accuracy: {accuracy_score(y_test, y_pred):.4f}")
print("\nClassification Report:\n", classification_report(y_test, y_pred))


# Normalized Confusion Matrix
cm = confusion_matrix(y_test, y_pred)

# Plot confusion matrix
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=["Predicted 0", "Predicted 1"],
            yticklabels=["Actual 0", "Actual 1"])
plt.title("Confusion Matrix-linear regression")
plt.xlabel("Predicted Label")
plt.ylabel("Actual Label")
plt.tight_layout()
plt.savefig("confusion_matrix_raw.png", dpi=300)
plt.show()


# ROC Curve
fpr, tpr, _ = roc_curve(y_test, y_pred_cont)
roc_auc = auc(fpr, tpr)
plt.figure(figsize=(6, 5))
plt.plot(fpr, tpr, label=f"AUC = {roc_auc:.4f}", color="darkorange")
plt.plot([0, 1], [0, 1], linestyle='--', color='gray')
plt.title("ROC Curve - Linear Regression")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend()
plt.tight_layout()
plt.savefig("linear_regression_roc_curve.png", dpi=300)
plt.show()

# Precision-Recall Curve
precision, recall, _ = precision_recall_curve(y_test, y_pred_cont)
plt.figure(figsize=(6, 5))
plt.plot(recall, precision, color="purple")
plt.title("Precision-Recall Curve")
plt.xlabel("Recall")
plt.ylabel("Precision-linear regression")
plt.tight_layout()
plt.savefig("linear_regression_precision_recall_curve.png", dpi=300)
plt.show()



# Install required packages
!pip install -q scikit-learn imbalanced-learn lightgbm matplotlib seaborn

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics import (
    accuracy_score, classification_report, confusion_matrix
)
from imblearn.over_sampling import SMOTE
from lightgbm import LGBMClassifier

# Load and prepare dataset
df = pd.read_csv("merge-csv.com__683fc98d75a00.csv", header=None)
df.columns = ["ID", "Sequence", "Label"]
df.dropna(subset=["Sequence", "Label"], inplace=True)
df["Label"] = pd.to_numeric(df["Label"], errors="coerce")
df.dropna(subset=["Label"], inplace=True)
df["Label"] = df["Label"].astype(int)

# K-mer encoding
def get_kmers(seq, k=4):
    return ' '.join([seq[i:i+k] for i in range(len(seq) - k + 1)])
df["kmers"] = df["Sequence"].str.upper().apply(lambda x: get_kmers(x, k=4))

# Vectorization
vectorizer = CountVectorizer(max_features=8000)
X = vectorizer.fit_transform(df["kmers"])
y = df["Label"]

# Train/Test split
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)

# SMOTE balancing
smote = SMOTE(random_state=42)
X_train_bal, y_train_bal = smote.fit_resample(X_train, y_train)

# Convert to float32 for LightGBM compatibility
X_train_bal = X_train_bal.astype(np.float32)
X_test = X_test.astype(np.float32)

# Train LightGBM
model = LGBMClassifier(
    n_estimators=300,
    learning_rate=0.05,
    max_depth=6,
    class_weight='balanced',
    random_state=42,
    n_jobs=-1
)
model.fit(X_train_bal, y_train_bal)

# Predict
y_pred = model.predict(X_test)
y_probs = model.predict_proba(X_test)[:, 1]

# Evaluation
print("LGBM Accuracy:", round(accuracy_score(y_test, y_pred), 4))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

# Assuming y_test and y_pred are already defined
# Compute confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Plot confusion matrix
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=["Predicted 0", "Predicted 1"],
            yticklabels=["Actual 0", "Actual 1"])
plt.title("Confusion Matrix-light gbm")
plt.xlabel("Predicted Label")
plt.ylabel("Actual Label")
plt.tight_layout()
plt.savefig("confusion_matrix_raw.png", dpi=300)
plt.show()

# ROC Curve
fpr, tpr, _ = roc_curve(y_test, y_pred_cont)
roc_auc = auc(fpr, tpr)
plt.figure(figsize=(6, 5))
plt.plot(fpr, tpr, label=f"AUC = {roc_auc:.4f}", color="darkorange")
plt.plot([0, 1], [0, 1], linestyle='--', color='gray')
plt.title("ROC Curve - light gbm")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend()
plt.tight_layout()
plt.savefig("linear_regression_roc_curve.png", dpi=300)
plt.show()

# Precision-Recall Curve
precision, recall, _ = precision_recall_curve(y_test, y_pred_cont)
plt.figure(figsize=(6, 5))
plt.plot(recall, precision, color="purple")
plt.title("Precision-Recall Curve-light gbm")
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.tight_layout()
plt.savefig("linear_regression_precision_recall_curve.png", dpi=300)
plt.show()

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import VotingClassifier
from sklearn.linear_model import RidgeClassifier
from sklearn.svm import SVC
from sklearn.linear_model import SGDClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from imblearn.over_sampling import SMOTE
from sklearn.feature_extraction.text import CountVectorizer
import seaborn as sns
import matplotlib.pyplot as plt

# Load and preprocess dataset (same as before)
df = pd.read_csv("merge-csv.com__683fc98d75a00.csv")
df = df.dropna(subset=["Unnamed: 1", "Unnamed: 2"])
df.columns = ["ID", "Sequence", "Label"]
df["Label"] = df["Label"].astype(int)
#df = df.sample(n=10000, random_state=42)

def get_kmers(seq, k=3):
    return ' '.join([seq[i:i+k] for i in range(len(seq) - k + 1)])

df["kmers"] = df["Sequence"].str.upper().apply(lambda x: get_kmers(x, k=3))

vectorizer = CountVectorizer()
X = vectorizer.fit_transform(df["kmers"])
y = df["Label"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

smote = SMOTE(random_state=42)
X_train_bal, y_train_bal = smote.fit_resample(X_train, y_train)

# Define base models
model1 = RidgeClassifier()
model2 = SVC(kernel='rbf', probability=True, random_state=42)
model3 = SGDClassifier(max_iter=1000, tol=1e-3, random_state=42)

# Voting classifier with 'hard' voting to avoid predict_proba error
voting_clf = VotingClassifier(
    estimators=[('ridge', model1), ('svc', model2), ('sgd', model3)],
    voting='hard'  # changed from 'soft' to 'hard'
)

# Train and predict
voting_clf.fit(X_train_bal, y_train_bal)
y_pred = voting_clf.predict(X_test)

print("Voting Classifier Accuracy:", accuracy_score(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))

cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='viridis', xticklabels=[0, 1], yticklabels=[0, 1])
plt.title("Voting Classifier Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()



# Install packages
!pip install -q scikit-learn imbalanced-learn matplotlib seaborn

import pandas as pd
import numpy as np  #  added missing import
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.ensemble import VotingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import (
    accuracy_score, classification_report, confusion_matrix,
    roc_curve, auc, precision_recall_curve
)
from imblearn.over_sampling import SMOTE
from sklearn.feature_extraction.text import CountVectorizer

# Load and preprocess dataset
df = pd.read_csv("merge-csv.com__683fc98d75a00.csv", header=None)
df.columns = ["ID", "Sequence", "Label"]
df.dropna(subset=["Sequence", "Label"], inplace=True)
df["Label"] = pd.to_numeric(df["Label"], errors="coerce")
df.dropna(subset=["Label"], inplace=True)
df["Label"] = df["Label"].astype(int)
df = df.sample(n=30000, random_state=42)

# K-mer conversion
def get_kmers(seq, k=4):
    return ' '.join([seq[i:i+k] for i in range(len(seq) - k + 1)])
df["kmers"] = df["Sequence"].str.upper().apply(lambda x: get_kmers(x, k=4))

# Vectorization
vectorizer = CountVectorizer()
X = vectorizer.fit_transform(df["kmers"])
y = df["Label"]

# Train/Test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)

# Balance the training data
smote = SMOTE(random_state=42)
X_train_bal, y_train_bal = smote.fit_resample(X_train, y_train)

# Define base models that support predict_proba
model1 = LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)
model2 = SVC(kernel='rbf', probability=True, class_weight='balanced', random_state=42)
model3 = MultinomialNB()

# VotingClassifier with soft voting
voting_clf = VotingClassifier(
    estimators=[('lr', model1), ('svc', model2), ('nb', model3)],
    voting='soft'
)

# Train and predict
voting_clf.fit(X_train_bal, y_train_bal)
y_pred = voting_clf.predict(X_test)
y_probs = voting_clf.predict_proba(X_test)[:, 1]  # for ROC & PR curves

# Evaluation
print("Voting Classifier Accuracy:", accuracy_score(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='viridis', xticklabels=[0, 1], yticklabels=[0, 1])
plt.title("Voting Classifier Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.show()

# Normalized Confusion Matrix
cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
plt.figure(figsize=(6, 5))
sns.heatmap(cm_norm, annot=True, fmt=".2f", cmap="Greens",
            xticklabels=["Pred 0", "Pred 1"], yticklabels=["Actual 0", "Actual 1"])
plt.title("Normalized Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.savefig("voting_classifier_confusion_matrix.png", dpi=300)
plt.show()

# ROC Curve
fpr, tpr, _ = roc_curve(y_test, y_probs)
roc_auc = auc(fpr, tpr)
plt.figure(figsize=(6, 5))
plt.plot(fpr, tpr, label=f"AUC = {roc_auc:.4f}", color="darkorange")
plt.plot([0, 1], [0, 1], linestyle='--', color='gray')
plt.title("ROC Curve - Voting Classifier")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend()
plt.tight_layout()
plt.savefig("voting_classifier_roc_curve.png", dpi=300)
plt.show()

# Precision-Recall Curve
precision, recall, _ = precision_recall_curve(y_test, y_probs)
plt.figure(figsize=(6, 5))
plt.plot(recall, precision, color="purple")
plt.title("Precision-Recall Curve - Voting Classifier")
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.tight_layout()
plt.savefig("voting_classifier_precision_recall_curve.png", dpi=300)
plt.show()



# Install required packages
!pip install -q scikit-learn imbalanced-learn matplotlib seaborn

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.ensemble import HistGradientBoostingClassifier
from sklearn.metrics import (
    accuracy_score, classification_report, confusion_matrix,
    roc_curve, auc, precision_recall_curve
)
from imblearn.over_sampling import SMOTE

# Load and preprocess dataset
df = pd.read_csv("merge-csv.com__683fc98d75a00.csv", header=None)
df.columns = ["ID", "Sequence", "Label"]
df.dropna(subset=["Sequence", "Label"], inplace=True)
df["Label"] = pd.to_numeric(df["Label"], errors="coerce")
df.dropna(subset=["Label"], inplace=True)
df["Label"] = df["Label"].astype(int)

# K-mer function
def get_kmers(seq, k=3):
    return ' '.join([seq[i:i+k] for i in range(len(seq) - k + 1)])
df["kmers"] = df["Sequence"].str.upper().apply(lambda x: get_kmers(x, k=3))

# Vectorization
vectorizer = CountVectorizer()
X = vectorizer.fit_transform(df["kmers"])
y = df["Label"]

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)

# SMOTE balancing
smote = SMOTE(random_state=42)
X_train_bal, y_train_bal = smote.fit_resample(X_train, y_train)

# Convert to dense
X_train_bal = X_train_bal.toarray()
X_test = X_test.toarray()

# Train HistGradientBoostingClassifier
model = HistGradientBoostingClassifier(max_iter=200, learning_rate=0.1, max_depth=10, random_state=42)
model.fit(X_train_bal, y_train_bal)

# Predict
y_pred = model.predict(X_test)
y_probs = model.predict_proba(X_test)[:, 1]  # Needed for ROC/PR curves

# Evaluation
acc = accuracy_score(y_test, y_pred)
print(f"HistGradientBoostingClassifier Accuracy: {acc:.4f}")
print(classification_report(y_test, y_pred))

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

# Assuming y_test and y_pred are already defined
# Compute confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Plot confusion matrix
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=["Predicted 0", "Predicted 1"],
            yticklabels=["Actual 0", "Actual 1"])
plt.title("Confusion Matrix-HistGradientBoosting")
plt.xlabel("Predicted Label")
plt.ylabel("Actual Label")
plt.tight_layout()
plt.savefig("confusion_matrix_raw.png", dpi=300)
plt.show()


# ROC Curve
fpr, tpr, _ = roc_curve(y_test, y_probs)
roc_auc = auc(fpr, tpr)
plt.figure(figsize=(6, 5))
plt.plot(fpr, tpr, label=f"AUC = {roc_auc:.4f}", color="darkorange")
plt.plot([0, 1], [0, 1], linestyle='--', color='gray')
plt.title("ROC Curve - HistGradientBoosting")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend()
plt.tight_layout()
plt.savefig("hist_gradient_roc_curve.png", dpi=300)
plt.show()

# Precision-Recall Curve
precision, recall, _ = precision_recall_curve(y_test, y_probs)
plt.figure(figsize=(6, 5))
plt.plot(recall, precision, color="purple")
plt.title("Precision-Recall Curve - HistGradientBoosting")
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.tight_layout()
plt.savefig("hist_gradient_pr_curve.png", dpi=300)
plt.show()



# Install required packages
!pip install -q scikit-learn imbalanced-learn matplotlib seaborn

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics import (
    accuracy_score, classification_report, confusion_matrix,
    roc_curve, auc, precision_recall_curve
)
from imblearn.over_sampling import SMOTE

# Load and preprocess dataset (no assumption about column names)
df = pd.read_csv("merge-csv.com__683fc98d75a00.csv", header=None)
df.columns = ["ID", "Sequence", "Label"]
df.dropna(subset=["Sequence", "Label"], inplace=True)
df["Label"] = pd.to_numeric(df["Label"], errors="coerce")
df.dropna(subset=["Label"], inplace=True)
df["Label"] = df["Label"].astype(int)

# K-mer feature extraction (k=3)
def get_kmers(seq, k=3):
    return ' '.join([seq[i:i+k] for i in range(len(seq) - k + 1)])
df["kmers"] = df["Sequence"].str.upper().apply(lambda x: get_kmers(x, k=3))

# Vectorize with CountVectorizer
vectorizer = CountVectorizer()
X = vectorizer.fit_transform(df["kmers"])
y = df["Label"]

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)

# Apply SMOTE to handle class imbalance
smote = SMOTE(random_state=42)
X_train_bal, y_train_bal = smote.fit_resample(X_train, y_train)

# Convert to dense (LinearRegression doesn't support sparse input)
X_train_bal = X_train_bal.toarray()
X_test = X_test.toarray()

# Train Linear Regression model
model = LinearRegression()
model.fit(X_train_bal, y_train_bal)

# Predict continuous outputs
y_pred_cont = model.predict(X_test)

# Apply threshold to convert to binary predictions
threshold = 0.5
y_pred = (y_pred_cont >= threshold).astype(int)

# Accuracy and classification report
acc = accuracy_score(y_test, y_pred)
print(f"Linear Regression Accuracy (threshold={threshold}): {acc:.4f}")
print("\nClassification Report:\n", classification_report(y_test, y_pred))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)

# Normalized Confusion Matrix
cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
plt.figure(figsize=(6, 5))
sns.heatmap(cm_norm, annot=True, fmt=".2f", cmap="Greens", xticklabels=["Pred 0", "Pred 1"], yticklabels=["Actual 0", "Actual 1"])
plt.title("Normalized Confusion Matrix - Multiple Linear Regression")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.savefig("linear_regression_normalized_confusion_matrix.png", dpi=300)
plt.show()

# ROC Curve
fpr, tpr, _ = roc_curve(y_test, y_pred_cont)
roc_auc = auc(fpr, tpr)
plt.figure(figsize=(6, 5))
plt.plot(fpr, tpr, label=f"AUC = {roc_auc:.4f}", color="darkorange")
plt.plot([0, 1], [0, 1], linestyle="--", color="gray")
plt.title("ROC Curve - Multiple Linear Regression")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend()
plt.tight_layout()
plt.savefig("linear_regression_roc_curve.png", dpi=300)
plt.show()

# Precision-Recall Curve
precision, recall, _ = precision_recall_curve(y_test, y_pred_cont)
plt.figure(figsize=(6, 5))
plt.plot(recall, precision, color="purple")
plt.title("Precision-Recall Curve - Multiple Linear Regression")
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.tight_layout()
plt.savefig("linear_regression_precision_recall_curve.png", dpi=300)
plt.show()



# Install required packages
!pip install -q scikit-learn imbalanced-learn matplotlib seaborn

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.decomposition import TruncatedSVD
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.metrics import (
    accuracy_score, classification_report, confusion_matrix,
    roc_curve, auc, precision_recall_curve
)
from imblearn.over_sampling import SMOTE

# Load dataset
df = pd.read_csv("merge-csv.com__683fc98d75a00.csv")

# Fix column names if only 3 columns
if df.shape[1] == 3:
    df.columns = ["ID", "Sequence", "Label"]

df = df.dropna(subset=["Sequence", "Label"])
df["Label"] = df["Label"].astype(int)

# K-mer function with k=6
def get_kmers(seq, k=6):
    return ' '.join([seq[i:i+k] for i in range(len(seq) - k + 1)])
df["kmers"] = df["Sequence"].str.upper().apply(lambda x: get_kmers(x, k=6))

# Vectorize
vectorizer = CountVectorizer()
X = vectorizer.fit_transform(df["kmers"])  # Sparse matrix
y = df["Label"]

# Reduce dimensionality
svd = TruncatedSVD(n_components=100, random_state=42)
X_reduced = svd.fit_transform(X)

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X_reduced, y, test_size=0.2, stratify=y, random_state=42
)

# SMOTE balancing
smote = SMOTE(random_state=42)
X_train_bal, y_train_bal = smote.fit_resample(X_train, y_train)

# Train LDA
model = LinearDiscriminantAnalysis()
model.fit(X_train_bal, y_train_bal)

# Predictions and probabilities
y_pred = model.predict(X_test)
y_probs = model.predict_proba(X_test)[:, 1]

# Accuracy and classification report
acc = accuracy_score(y_test, y_pred)
print(f"\nLinear Discriminant Analysis (k=6 + SVD) Accuracy: {acc:.4f}")
print("\nClassification Report:\n", classification_report(y_test, y_pred))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title("Confusion Matrix - LDA (SVD Reduced)")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.show()

# Normalized Confusion Matrix
cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
plt.figure(figsize=(6, 5))
sns.heatmap(cm_norm, annot=True, fmt=".2f", cmap="Greens")
plt.title("Normalized Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.show()

# ROC Curve
fpr, tpr, _ = roc_curve(y_test, y_probs)
roc_auc = auc(fpr, tpr)
plt.figure(figsize=(6, 5))
plt.plot(fpr, tpr, label=f"AUC = {roc_auc:.4f}", color="darkorange")
plt.plot([0, 1], [0, 1], linestyle="--", color="gray")
plt.title("ROC Curve - LDA (SVD Reduced)")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend()
plt.tight_layout()
plt.show()

# Precision-Recall Curve
precision, recall, _ = precision_recall_curve(y_test, y_probs)
plt.figure(figsize=(6, 5))
plt.plot(recall, precision, color="purple")
plt.title("Precision-Recall Curve - LDA (SVD Reduced)")
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.tight_layout()
plt.show()

# Install required packages
!pip install -q scikit-learn imbalanced-learn matplotlib seaborn

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.decomposition import PCA
from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis
from sklearn.metrics import (
    accuracy_score, classification_report, confusion_matrix,
    roc_curve, auc, precision_recall_curve
)
from imblearn.over_sampling import SMOTE

# Load dataset
df = pd.read_csv("merge-csv.com__683fc98d75a00.csv")

# Automatically assign proper column names if only 3 columns are present
if df.shape[1] == 3:
    df.columns = ["ID", "Sequence", "Label"]

# Drop rows with missing Sequence or Label
df = df.dropna(subset=["Sequence", "Label"])
df["Label"] = df["Label"].astype(int)

# K-mer conversion with k=6
def get_kmers(seq, k=6):
    return ' '.join([seq[i:i+k] for i in range(len(seq) - k + 1)])

df["kmers"] = df["Sequence"].str.upper().apply(lambda x: get_kmers(x, k=6))

# Convert k-mers into numerical feature vectors
vectorizer = CountVectorizer()
X = vectorizer.fit_transform(df["kmers"])
y = df["Label"]

# Train-test split (stratified)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

# Balance the training data using SMOTE
smote = SMOTE(random_state=42)
X_train_bal, y_train_bal = smote.fit_resample(X_train, y_train)

# Convert to dense arrays for QDA
X_train_bal = X_train_bal.toarray()
X_test = X_test.toarray()

# Apply PCA to reduce dimensionality for QDA
pca = PCA(n_components=100)
X_train_pca = pca.fit_transform(X_train_bal)
X_test_pca = pca.transform(X_test)

# Train the QDA model
model = QuadraticDiscriminantAnalysis()
model.fit(X_train_pca, y_train_bal)

# Predictions and probability scores
y_pred = model.predict(X_test_pca)
y_probs = model.predict_proba(X_test_pca)[:, 1]

# Evaluation
acc = accuracy_score(y_test, y_pred)
print(f"\nQuadratic Discriminant Analysis Accuracy (k=6): {acc:.4f}")
print("\nClassification Report:\n", classification_report(y_test, y_pred))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[0, 1], yticklabels=[0, 1])
plt.title("QDA Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.show()

# Normalized Confusion Matrix
cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
plt.figure(figsize=(6, 5))
sns.heatmap(cm_norm, annot=True, fmt=".2f", cmap="Greens", xticklabels=["Pred 0", "Pred 1"], yticklabels=["Actual 0", "Actual 1"])
plt.title("Normalized Confusion Matrix - QDA (k=6)")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.savefig("qda_k6_normalized_confusion_matrix.png", dpi=300)
plt.show()

# ROC Curve
fpr, tpr, _ = roc_curve(y_test, y_probs)
roc_auc = auc(fpr, tpr)
plt.figure(figsize=(6, 5))
plt.plot(fpr, tpr, label=f"AUC = {roc_auc:.4f}", color="darkorange")
plt.plot([0, 1], [0, 1], linestyle="--", color="gray")
plt.title("ROC Curve - QDA (k=6)")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend()
plt.tight_layout()
plt.savefig("qda_k6_roc_curve.png", dpi=300)
plt.show()

# Precision-Recall Curve
precision, recall, _ = precision_recall_curve(y_test, y_probs)
plt.figure(figsize=(6, 5))
plt.plot(recall, precision, color="purple")
plt.title("Precision-Recall Curve - QDA (k=6)")
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.tight_layout()
plt.savefig("qda_k6_precision_recall_curve.png", dpi=300)
plt.show()



# Install required packages
!pip install -q scikit-learn matplotlib seaborn

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.gaussian_process import GaussianProcessClassifier
from sklearn.gaussian_process.kernels import RBF
from sklearn.metrics import (
    accuracy_score, classification_report, confusion_matrix,
    f1_score, roc_curve, auc, precision_recall_curve
)

# Load dataset
df = pd.read_csv(
    "/content/merge-csv.com__683fc98d75a00.csv",
    names=["id", "sequence", "label"],
    skiprows=1,
    dtype={"id": str, "sequence": str, "label": str},
    low_memory=False
)

# Preprocess
df.dropna(subset=["sequence", "label"], inplace=True)
df = df[df["label"].str.isnumeric()]
df["label"] = df["label"].astype(int)
df["sequence"] = df["sequence"].str.lower()

# Split dataset (train-test only)
train_df, test_df = train_test_split(df, test_size=0.2, stratify=df["label"], random_state=42)

# Balance training data
target_min = train_df["label"].value_counts().min()
train_df_bal = pd.concat([
    train_df[train_df["label"] == 0].sample(target_min, random_state=42),
    train_df[train_df["label"] == 1].sample(target_min, random_state=42)
]).sample(frac=1, random_state=42)

# K-mer function
def get_kmers(seq, k=6):
    return " ".join([seq[i:i+k] for i in range(len(seq) - k + 1)])

X_train_kmers = train_df_bal["sequence"].apply(get_kmers)
X_test_kmers = test_df["sequence"].apply(get_kmers)

# TF-IDF vectorization
vectorizer = TfidfVectorizer(analyzer="char", ngram_range=(4, 8), max_features=30000)
X_train = vectorizer.fit_transform(X_train_kmers)
X_test = vectorizer.transform(X_test_kmers)

y_train = train_df_bal["label"]
y_test = test_df["label"]

# Train Gaussian Process Classifier
kernel = 1.0 * RBF(length_scale=1.0)
model = GaussianProcessClassifier(kernel=kernel, random_state=42, max_iter_predict=100)
model.fit(X_train.toarray(), y_train)

# Predict probabilities
test_probs = model.predict_proba(X_test.toarray())[:, 1]

# Threshold tuning using test set directly
best_thresh, best_f1 = 0.5, 0
for t in np.arange(0.1, 0.9, 0.01):
    preds = (test_probs >= t).astype(int)
    f1 = f1_score(y_test, preds)
    if f1 > best_f1:
        best_thresh, best_f1 = t, f1

# Final predictions
test_pred = (test_probs >= best_thresh).astype(int)

# Evaluation
acc = accuracy_score(y_test, test_pred)
print(f"\nGaussianProcessClassifier Accuracy: {acc:.4f}")
print("\nClassification Report:\n", classification_report(y_test, test_pred, digits=4))

# Confusion Matrix
cm = confusion_matrix(y_test, test_pred)
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=["Predicted 0", "Predicted 1"], yticklabels=["Actual 0", "Actual 1"])
plt.title("Confusion Matrix - GaussianProcessClassifier")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.tight_layout()
plt.show()

# Normalized Confusion Matrix
cm_norm = cm.astype("float") / cm.sum(axis=1)[:, np.newaxis]
plt.figure(figsize=(6, 5))
sns.heatmap(cm_norm, annot=True, fmt=".2f", cmap="Greens", xticklabels=["Predicted 0", "Predicted 1"], yticklabels=["Actual 0", "Actual 1"])
plt.title("Normalized Confusion Matrix - GaussianProcessClassifier")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.tight_layout()
plt.savefig("gaussian_confusion_matrix_normalized.png", dpi=300)
plt.show()

# ROC Curve
fpr, tpr, _ = roc_curve(y_test, test_probs)
roc_auc = auc(fpr, tpr)
plt.figure(figsize=(6, 5))
plt.plot(fpr, tpr, color="darkorange", lw=2, label=f"ROC curve (AUC = {roc_auc:.4f})")
plt.plot([0, 1], [0, 1], linestyle="--", color="navy")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve - GaussianProcessClassifier")
plt.legend(loc="lower right")
plt.tight_layout()
plt.savefig("gaussian_roc_curve.png", dpi=300)
plt.show()

# Precision-Recall Curve
precision, recall, _ = precision_recall_curve(y_test, test_probs)
plt.figure(figsize=(6, 5))
plt.plot(recall, precision, color="purple")
plt.title("Precision-Recall Curve - GaussianProcessClassifier")
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.tight_layout()
plt.savefig("gaussian_precision_recall_curve.png", dpi=300)
plt.show()





import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import (
    accuracy_score, classification_report, confusion_matrix,
    roc_curve, auc, precision_recall_curve
)
from xgboost import XGBClassifier
from imblearn.over_sampling import SMOTE
import matplotlib.pyplot as plt
import seaborn as sns

# 1. Load and clean dataset
df = pd.read_csv("merge-csv.com__683fc98d75a00.csv", names=["ID", "Sequence", "Label"], skiprows=1)
df.dropna(subset=["Sequence", "Label"], inplace=True)
df["Label"] = pd.to_numeric(df["Label"], errors="coerce")
df.dropna(subset=["Label"], inplace=True)
df["Label"] = df["Label"].astype(int)

# 2. Extract 6-mers
def get_kmers(seq, k=6):
    return ' '.join([seq[i:i+k] for i in range(len(seq) - k + 1)])

df["kmers"] = df["Sequence"].str.upper().apply(lambda x: get_kmers(x, k=6))

# 3. TF-IDF
vectorizer = TfidfVectorizer()
X = vectorizer.fit_transform(df["kmers"])
y = df["Label"]

# 4. Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

# 5. SMOTE for balance
smote = SMOTE(random_state=42)
X_train_bal, y_train_bal = smote.fit_resample(X_train, y_train)

# 6. XGBoost with tuned params
model = XGBClassifier(
    use_label_encoder=False,
    eval_metric='logloss',
    learning_rate=0.05,
    max_depth=7,
    n_estimators=500,
    subsample=0.8,
    colsample_bytree=0.8,
    n_jobs=-1,
    random_state=42
)
model.fit(X_train_bal, y_train_bal)

# 7. Predict & Evaluate
y_pred = model.predict(X_test)
y_probs = model.predict_proba(X_test)[:, 1]  # For ROC & PR curves

print(" Accuracy:", accuracy_score(y_test, y_pred))
print(" Classification Report:\n", classification_report(y_test, y_pred))

# 8. Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', xticklabels=[0, 1], yticklabels=[0, 1])
plt.title("Confusion Matrix - Tuned XGBoost")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.show()

# 9. Normalized Confusion Matrix
cm_norm = cm.astype("float") / cm.sum(axis=1)[:, np.newaxis]
plt.figure(figsize=(6, 5))
sns.heatmap(cm_norm, annot=True, fmt=".2f", cmap="YlGnBu",
            xticklabels=["Pred 0", "Pred 1"],
            yticklabels=["Actual 0", "Actual 1"])
plt.title("Normalized Confusion Matrix -tuned XGBoost")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.savefig("xgboost_normalized_confusion_matrix.png", dpi=300)
plt.show()

# 10. ROC Curve
fpr, tpr, _ = roc_curve(y_test, y_probs)
roc_auc = auc(fpr, tpr)
plt.figure(figsize=(6, 5))
plt.plot(fpr, tpr, color="darkorange", label=f"ROC curve (AUC = {roc_auc:.4f})")
plt.plot([0, 1], [0, 1], linestyle="--", color="gray")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve - XGBoost")
plt.legend(loc="lower right")
plt.tight_layout()
plt.savefig("xgboost_roc_curve.png", dpi=300)
plt.show()

# 11. Precision-Recall Curve
precision, recall, _ = precision_recall_curve(y_test, y_probs)
plt.figure(figsize=(6, 5))
plt.plot(recall, precision, color="purple")
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.title("Precision-Recall Curve - Tuned XGBoost")
plt.tight_layout()
plt.savefig("xgboost_precision_recall_curve.png", dpi=300)
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (
    accuracy_score, classification_report, confusion_matrix,
    f1_score, roc_curve, auc, precision_recall_curve
)

# Load dataset
df = pd.read_csv(
    "/content/merge-csv.com__683fc98d75a00.csv",
    names=["id", "sequence", "label"],
    skiprows=1,
    dtype={"id": str, "sequence": str, "label": str},
    low_memory=False
)

# Preprocess
df.dropna(subset=["sequence", "label"], inplace=True)
df = df[df["label"].str.isnumeric()]
df["label"] = df["label"].astype(int)
df["sequence"] = df["sequence"].str.lower()

# Split into train, validation, and test
train_df, temp_df = train_test_split(df, test_size=0.4, stratify=df["label"], random_state=42)
val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df["label"], random_state=42)

# Balance training set
target_min = train_df["label"].value_counts().min()
train_df_bal = pd.concat([
    train_df[train_df["label"] == 0].sample(target_min, random_state=42),
    train_df[train_df["label"] == 1].sample(target_min, random_state=42)
]).sample(frac=1, random_state=42)

# K-mer generation
def get_kmers(seq, k=6):
    return " ".join([seq[i:i+k] for i in range(len(seq) - k + 1)])

X_train_kmers = train_df_bal["sequence"].apply(get_kmers)
X_val_kmers = val_df["sequence"].apply(get_kmers)
X_test_kmers = test_df["sequence"].apply(get_kmers)

# TF-IDF Vectorization
vectorizer = TfidfVectorizer(analyzer="char", ngram_range=(4, 8), max_features=30000)
X_train = vectorizer.fit_transform(X_train_kmers)
X_val = vectorizer.transform(X_val_kmers)
X_test = vectorizer.transform(X_test_kmers)

y_train = train_df_bal["label"]
y_val = val_df["label"]
y_test = test_df["label"]

# Train Random Forest
model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)
model.fit(X_train, y_train)

# Predict probabilities
val_probs = model.predict_proba(X_val)[:, 1]
test_probs = model.predict_proba(X_test)[:, 1]

# Threshold tuning
best_thresh, best_f1 = 0.5, 0
for t in np.arange(0.1, 0.9, 0.01):
    preds = (val_probs >= t).astype(int)
    f1 = f1_score(y_val, preds)
    if f1 > best_f1:
        best_thresh, best_f1 = t, f1

# Final prediction
test_pred = (test_probs >= best_thresh).astype(int)

# Evaluation
acc = accuracy_score(y_test, test_pred)
print(f"Random Forest Accuracy: {acc:.4f}\n")
print(classification_report(y_test, test_pred, digits=4))

# --- Confusion Matrix ---
cm = confusion_matrix(y_test, test_pred)
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", cbar=False,
            xticklabels=["Predicted 0", "Predicted 1"],
            yticklabels=["Actual 0", "Actual 1"])
plt.title("Confusion Matrix - Random Forest")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.tight_layout()
plt.savefig("randomforest_confusion_matrix.png")
plt.show()

# --- Normalized Confusion Matrix ---
cm_norm = cm.astype("float") / cm.sum(axis=1)[:, np.newaxis]
plt.figure(figsize=(6, 5))
sns.heatmap(cm_norm, annot=True, fmt=".2f", cmap="Greens", cbar=False,
            xticklabels=["Predicted 0", "Predicted 1"],
            yticklabels=["Actual 0", "Actual 1"])
plt.title("Normalized Confusion Matrix - Random Forest")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.tight_layout()
plt.savefig("randomforest_confusion_matrix_normalized.png", dpi=300)
plt.show()

# --- ROC Curve ---
fpr, tpr, _ = roc_curve(y_test, test_probs)
roc_auc = auc(fpr, tpr)
plt.figure(figsize=(6, 5))
plt.plot(fpr, tpr, color="darkorange", lw=2, label=f"AUC = {roc_auc:.4f}")
plt.plot([0, 1], [0, 1], linestyle="--", color="gray")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve - Random Forest")
plt.legend(loc="lower right")
plt.tight_layout()
plt.savefig("randomforest_roc_curve.png", dpi=300)
plt.show()

# --- Precision-Recall Curve ---
precision, recall, _ = precision_recall_curve(y_test, test_probs)
plt.figure(figsize=(6, 5))
plt.plot(recall, precision, color="purple")
plt.title("Precision-Recall Curve - Random Forest")
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.tight_layout()
plt.savefig("randomforest_precision_recall_curve.png", dpi=300)
plt.show()



import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.linear_model import RidgeClassifier
from sklearn.metrics import (
    accuracy_score, classification_report, confusion_matrix,
    roc_curve, auc, precision_recall_curve
)
from imblearn.over_sampling import SMOTE
from sklearn.feature_extraction.text import TfidfVectorizer
import matplotlib.pyplot as plt
import seaborn as sns

# 1. Load and preprocess dataset
df = pd.read_csv("merge-csv.com__683fc98d75a00.csv", header=None)
df.columns = ["ID", "Sequence", "Label"]
df.dropna(subset=["Sequence", "Label"], inplace=True)
df["Label"] = pd.to_numeric(df["Label"], errors='coerce')
df.dropna(subset=["Label"], inplace=True)
df["Label"] = df["Label"].astype(int)
#df = df.sample(n=10000, random_state=42)

# 2. k-mer feature extraction
def get_kmers(seq, k=4):
    return ' '.join([seq[i:i+k] for i in range(len(seq) - k + 1)])
df["kmers"] = df["Sequence"].str.upper().apply(lambda x: get_kmers(x, k=4))

# 3. TF-IDF vectorization
vectorizer = TfidfVectorizer(max_features=5000)
X = vectorizer.fit_transform(df["kmers"])
y = df["Label"]

# 4. Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)

# 5. SMOTE for class balancing
smote = SMOTE(random_state=42)
X_train_bal, y_train_bal = smote.fit_resample(X_train, y_train)

# 6. GridSearchCV for Ridge Classifier
param_grid = {'alpha': [0.01, 0.1, 1.0, 10.0, 100.0]}
ridge = RidgeClassifier()
grid = GridSearchCV(ridge, param_grid, scoring='accuracy', cv=3, n_jobs=-1)
grid.fit(X_train_bal, y_train_bal)

# 7. Best model
print("Best Parameters:", grid.best_params_)
print("Best Cross-Validation Accuracy:", grid.best_score_)

# 8. Evaluate on test set
best_ridge = grid.best_estimator_
y_pred = best_ridge.predict(X_test)

print("Test Accuracy:", accuracy_score(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))

# 9. Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[0, 1], yticklabels=[0, 1])
plt.title("Confusion Matrix - Ridge Classifier")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.show()

# 10. Normalized Confusion Matrix
cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
plt.figure(figsize=(6, 5))
sns.heatmap(cm_norm, annot=True, fmt=".2f", cmap="YlGnBu",
            xticklabels=["Predicted 0", "Predicted 1"],
            yticklabels=["Actual 0", "Actual 1"])
plt.title("Normalized Confusion Matrix - Ridge Classifier")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.savefig("ridge_normalized_confusion_matrix.png", dpi=300)
plt.show()

# 11. ROC Curve
# Since RidgeClassifier doesn't support predict_proba, simulate using decision_function
y_scores = best_ridge.decision_function(X_test)
fpr, tpr, _ = roc_curve(y_test, y_scores)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(6, 5))
plt.plot(fpr, tpr, color='darkorange', label=f"AUC = {roc_auc:.4f}")
plt.plot([0, 1], [0, 1], linestyle='--', color='gray')
plt.title("ROC Curve - Ridge Classifier")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend()
plt.tight_layout()
plt.savefig("ridge_roc_curve.png", dpi=300)
plt.show()

# 12. Precision-Recall Curve
precision, recall, _ = precision_recall_curve(y_test, y_scores)
plt.figure(figsize=(6, 5))
plt.plot(recall, precision, color="purple")
plt.title("Precision-Recall Curve - Ridge Classifier")
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.tight_layout()
plt.savefig("ridge_precision_recall_curve.png", dpi=300)
plt.show()



import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import (
    accuracy_score, classification_report, confusion_matrix,
    roc_curve, auc, precision_recall_curve
)
from xgboost import XGBClassifier
from imblearn.over_sampling import SMOTE
import matplotlib.pyplot as plt
import seaborn as sns

# 1. Load dataset and fix column names
df = pd.read_csv("merge-csv.com__683fc98d75a00.csv", header=None)
df.columns = ["ID", "Sequence", "Label"]
df.dropna(subset=["Sequence", "Label"], inplace=True)
df["Label"] = pd.to_numeric(df["Label"], errors="coerce")
df.dropna(subset=["Label"], inplace=True)
df["Label"] = df["Label"].astype(int)

# (Optional) Limit to 10,000 rows for performance
#df = df.sample(n=10000, random_state=42)

# 2. Extract 6-mers
def get_kmers(seq, k=6):
    return ' '.join([seq[i:i+k] for i in range(len(seq) - k + 1)])
df["kmers"] = df["Sequence"].str.upper().apply(lambda x: get_kmers(x, k=6))

# 3. TF-IDF
vectorizer = TfidfVectorizer()
X = vectorizer.fit_transform(df["kmers"])
y = df["Label"]

# 4. Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)

# 5. SMOTE for balance
smote = SMOTE(random_state=42)
X_train_bal, y_train_bal = smote.fit_resample(X_train, y_train)

# 6. XGBoost
model = XGBClassifier(
    use_label_encoder=False,
    eval_metric='logloss',
    learning_rate=0.05,
    max_depth=7,
    n_estimators=500,
    subsample=0.8,
    colsample_bytree=0.8,
    n_jobs=-1,
    random_state=42
)
model.fit(X_train_bal, y_train_bal)

# 7. Predictions
y_pred = model.predict(X_test)
y_probs = model.predict_proba(X_test)[:, 1]  # For ROC & PR curves

# 8. Accuracy & Report
print(" Accuracy:", accuracy_score(y_test, y_pred))
print(" Classification Report:\n", classification_report(y_test, y_pred))

# 9. Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', xticklabels=[0, 1], yticklabels=[0, 1])
plt.title("Confusion Matrix: XGBoost")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.savefig("xgboost_confusion_matrix.png")
plt.show()

# 10. Normalized Confusion Matrix
cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
plt.figure(figsize=(6, 5))
sns.heatmap(cm_norm, annot=True, fmt=".2f", cmap="YlGnBu",
            xticklabels=["Predicted 0", "Predicted 1"],
            yticklabels=["Actual 0", "Actual 1"])
plt.title("Normalized Confusion Matrix - XGBoost")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.savefig("xgboost_normalized_confusion_matrix.png")
plt.show()

# 11. ROC Curve
fpr, tpr, _ = roc_curve(y_test, y_probs)
roc_auc = auc(fpr, tpr)
plt.figure(figsize=(6, 5))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f"AUC = {roc_auc:.4f}")
plt.plot([0, 1], [0, 1], linestyle='--', color='navy')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve - XGBoost")
plt.legend(loc="lower right")
plt.tight_layout()
plt.savefig("xgboost_roc_curve.png", dpi=300)
plt.show()

# 12. Precision-Recall Curve
precision, recall, _ = precision_recall_curve(y_test, y_probs)
plt.figure(figsize=(6, 5))
plt.plot(recall, precision, color="purple")
plt.title("Precision-Recall Curve - XGBoost")
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.tight_layout()
plt.savefig("xgboost_precision_recall_curve.png", dpi=300)
plt.show()



import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import StackingClassifier
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc, precision_recall_curve
from imblearn.over_sampling import SMOTE
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.svm import SVC
from scipy.sparse import csr_matrix

# Load dataset
df = pd.read_csv("merge-csv.com__683fc98d75a00.csv", header=None, names=["ID", "Sequence", "Label"])
df.dropna(subset=["Sequence", "Label"], inplace=True)
df["Label"] = pd.to_numeric(df["Label"], errors="coerce")
df.dropna(subset=["Label"], inplace=True)
df["Label"] = df["Label"].astype(int)

# Reduce size to avoid RAM crash
df = df.sample(n=5000, random_state=42)

# K-mers
def get_kmers(seq, k=4):
    return ' '.join([seq[i:i+k] for i in range(len(seq) - k + 1)])
df["kmers"] = df["Sequence"].str.upper().apply(get_kmers)

# TF-IDF
vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(4, 6), max_features=5000)
X = vectorizer.fit_transform(df["kmers"])
y = df["Label"]

# Split
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)

# SMOTE
smote = SMOTE(random_state=42)
X_train_bal, y_train_bal = smote.fit_resample(X_train, y_train)

# Ensure writeable matrix for XGBoost
if isinstance(X_train_bal, csr_matrix):
    X_train_bal = X_train_bal.tocsr().copy()
    X_train_bal.sort_indices()
    X_train_bal.data = np.copy(X_train_bal.data)

# Base learners
xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', max_depth=5, n_estimators=150, learning_rate=0.1, random_state=42)
svc = SVC(kernel='linear', probability=True, C=1.0, random_state=42)

# Meta learner
meta = LogisticRegression(max_iter=1000, random_state=42)

# Stacking classifier
stack_model = StackingClassifier(
    estimators=[('xgb', xgb), ('svc', svc)],
    final_estimator=meta,
    passthrough=True,
    cv=5,
    n_jobs=-1
)

# Fit model
stack_model.fit(X_train_bal, y_train_bal)

# Predict
y_pred = stack_model.predict(X_test)
y_probs = stack_model.predict_proba(X_test)[:, 1]

# Evaluation
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[0, 1], yticklabels=[0, 1])
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.show()

# Normalized
cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
plt.figure(figsize=(6, 5))
sns.heatmap(cm_norm, annot=True, fmt=".2f", cmap="YlGnBu",
            xticklabels=["Pred 0", "Pred 1"], yticklabels=["Actual 0", "Actual 1"])
plt.title("Normalized Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.show()

# ROC
fpr, tpr, _ = roc_curve(y_test, y_probs)
roc_auc = auc(fpr, tpr)
plt.figure()
plt.plot(fpr, tpr, label=f"AUC = {roc_auc:.4f}", color="darkorange")
plt.plot([0, 1], [0, 1], linestyle='--', color='gray')
plt.title("ROC Curve - Stacking Classifier")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend()
plt.tight_layout()
plt.show()

# Precision-Recall
precision, recall, _ = precision_recall_curve(y_test, y_probs)
plt.figure()
plt.plot(recall, precision, color="purple")
plt.title("Precision-Recall Curve")
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.tight_layout()
plt.show()

# Install packages
!pip install -q scikit-learn matplotlib seaborn

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.utils import resample
from sklearn.metrics import (
    accuracy_score, classification_report, confusion_matrix,
    roc_curve, auc, precision_recall_curve, f1_score
)

# Set seed
np.random.seed(42)

# Load dataset
df = pd.read_csv("merge-csv.com__683fc98d75a00.csv", names=["id", "sequence", "label"], skiprows=1)
df.dropna(subset=["sequence", "label"], inplace=True)
df["label"] = pd.to_numeric(df["label"], errors='coerce')
df.dropna(subset=["label"], inplace=True)
df["label"] = df["label"].astype(int)
df["sequence"] = df["sequence"].str.lower()
df = df[df["sequence"].str.len() >= 6]

# Generate k-mers
def get_kmers(seq, k=6):
    return " ".join([seq[i:i+k] for i in range(len(seq)-k+1)])
df["kmers"] = df["sequence"].apply(get_kmers)

# Balance dataset
df_major = df[df["label"] == 0]
df_minor = df[df["label"] == 1]
df_minor_upsampled = resample(df_minor, replace=True, n_samples=len(df_major), random_state=42)
df_balanced = pd.concat([df_major, df_minor_upsampled]).sample(frac=1, random_state=42)

# TF-IDF Vectorization
vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(4, 6), max_features=10000)
X = vectorizer.fit_transform(df_balanced["kmers"])
y = df_balanced["label"].values

# Get feature names (k-mers) and IDF values
feature_names = vectorizer.get_feature_names_out()
idf_values = vectorizer.idf_

# printing the IDF scores
idf_df = pd.DataFrame({
    "k-mer": feature_names,
    "IDF": idf_values
}).sort_values(by="IDF", ascending=False)

print(idf_df.head(10))


# Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)

# Train Multinomial Naive Bayes
model = MultinomialNB()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
y_probs = model.predict_proba(X_test)[:, 1]

# Evaluation
print("Accuracy:", round(accuracy_score(y_test, y_pred), 4))
print("\nClassification Report:\n", classification_report(y_test, y_pred, digits=4))

# evaluting how the confusion matrix will form
df_results = pd.DataFrame({
    'Index': np.arange(len(y_test)),
    'Actual': y_test,
    'Predicted': y_pred
})

def get_outcome(actual, predicted):
    if actual == 1 and predicted == 1:
        return ' TP'
    elif actual == 0 and predicted == 0:
        return ' TN'
    elif actual == 0 and predicted == 1:
        return ' FP'
    elif actual == 1 and predicted == 0:
        return ' FN'

df_results["Outcome"] = df_results.apply(lambda row: get_outcome(row["Actual"], row["Predicted"]), axis=1)

# Display a few rows
print("\nSample prediction outcomes:")
print(df_results.head(10))

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

# Assuming y_test and y_pred are already defined
# Compute confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Plot confusion matrix
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=["Predicted 0", "Predicted 1"],
            yticklabels=["Actual 0", "Actual 1"])
plt.title("Confusion Matrix-MultinomialNB")
plt.xlabel("Predicted Label")
plt.ylabel("Actual Label")
plt.tight_layout()
plt.savefig("confusion_matrix_raw.png", dpi=300)
plt.show()


# Normalized Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
plt.figure(figsize=(6, 5))
sns.heatmap(cm_norm, annot=True, cmap="Greens", cbar=False,
            xticklabels=["Pred 0", "Pred 1"], yticklabels=["Actual 0", "Actual 1"])
plt.title("Normalized Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.savefig("normalized_confusion_matrix.png", dpi=300)
plt.show()

# ROC Curve
fpr, tpr, _ = roc_curve(y_test, y_probs)
roc_auc = auc(fpr, tpr)
plt.figure(figsize=(6, 5))
plt.plot(fpr, tpr, color='darkorange', label=f"ROC curve (AUC = {roc_auc:.4f})")
plt.plot([0, 1], [0, 1], linestyle='--', color='navy')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve - MultinomialNB")
plt.legend()
plt.tight_layout()
plt.savefig("roc_curve.png", dpi=300)
plt.show()

# Precision-Recall Curve
precision, recall, _ = precision_recall_curve(y_test, y_probs)
plt.figure(figsize=(6, 5))
plt.plot(recall, precision, color="purple")
plt.title("Precision-Recall Curve-MultinomialNB")
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.tight_layout()
plt.savefig("precision_recall_curve.png", dpi=300)
plt.show()

# Install packages
!pip install -q scikit-learn matplotlib seaborn

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.utils import resample
from sklearn.metrics import (
    accuracy_score, classification_report, confusion_matrix,
    roc_curve, auc, precision_recall_curve, f1_score
)

# Set seed
np.random.seed(42)

# Load dataset
df = pd.read_csv("merge-csv.com__683fc98d75a00.csv", names=["id", "sequence", "label"], skiprows=1)
df.dropna(subset=["sequence", "label"], inplace=True)
df["label"] = pd.to_numeric(df["label"], errors='coerce')
df.dropna(subset=["label"], inplace=True)
df["label"] = df["label"].astype(int)
df["sequence"] = df["sequence"].str.lower()
df = df[df["sequence"].str.len() >= 6]

# Generate k-mers
def get_kmers(seq, k=6):
    return " ".join([seq[i:i+k] for i in range(len(seq)-k+1)])
df["kmers"] = df["sequence"].apply(get_kmers)

# Balance dataset
df_major = df[df["label"] == 0]
df_minor = df[df["label"] == 1]
df_minor_upsampled = resample(df_minor, replace=True, n_samples=len(df_major), random_state=42)
df_balanced = pd.concat([df_major, df_minor_upsampled]).sample(frac=1, random_state=42)

# TF-IDF Vectorization
vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(4, 6), max_features=10000)
X = vectorizer.fit_transform(df_balanced["kmers"])
y = df_balanced["label"].values

# Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)

# Train Multinomial Naive Bayes
model = MultinomialNB()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
y_probs = model.predict_proba(X_test)[:, 1]

# Evaluation
print("Accuracy:", round(accuracy_score(y_test, y_pred), 4))
print("\nClassification Report:\n", classification_report(y_test, y_pred, digits=4))
# Outcome Logic (TP, TN, FP, FN)

df_results = pd.DataFrame({
    'Index': np.arange(len(y_test)),
    'Actual': y_test,
    'Predicted': y_pred
})

def get_outcome(actual, predicted):
    if actual == 1 and predicted == 1:
        return ' TP'
    elif actual == 0 and predicted == 0:
        return ' TN'
    elif actual == 0 and predicted == 1:
        return ' FP'
    elif actual == 1 and predicted == 0:
        return ' FN'

df_results["Outcome"] = df_results.apply(lambda row: get_outcome(row["Actual"], row["Predicted"]), axis=1)

# Display a few rows
print("\nSample prediction outcomes:")
print(df_results.head(10))


# Normalized Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
plt.figure(figsize=(6, 5))
sns.heatmap(cm_norm, annot=True, fmt=".2f", cmap="Greens", cbar=False,
            xticklabels=["Pred 0", "Pred 1"], yticklabels=["Actual 0", "Actual 1"])
plt.title("Normalized Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.savefig("normalized_confusion_matrix.png", dpi=300)
plt.show()

# ROC Curve
fpr, tpr, _ = roc_curve(y_test, y_probs)
roc_auc = auc(fpr, tpr)
plt.figure(figsize=(6, 5))
plt.plot(fpr, tpr, color='darkorange', label=f"ROC curve (AUC = {roc_auc:.4f})")
plt.plot([0, 1], [0, 1], linestyle='--', color='navy')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve - MultinomialNB")
plt.legend()
plt.tight_layout()
plt.savefig("roc_curve.png", dpi=300)
plt.show()

# Precision-Recall Curve
precision, recall, _ = precision_recall_curve(y_test, y_probs)
plt.figure(figsize=(6, 5))
plt.plot(recall, precision, color="purple")
plt.title("Precision-Recall Curve")
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.tight_layout()
plt.savefig("precision_recall_curve.png", dpi=300)
plt.show()

# Set seed
#np.random.seed(42)
# Install packages
!pip install -q scikit-learn matplotlib seaborn

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import BernoulliNB
from sklearn.utils import resample
from sklearn.metrics import (
    accuracy_score, classification_report, confusion_matrix,
    roc_curve, auc, precision_recall_curve, f1_score
)

# Load dataset
df = pd.read_csv("merge-csv.com__683fc98d75a00.csv", names=["id", "sequence", "label"], skiprows=1)

#preprocessing the dataset
df.dropna(subset=["sequence", "label"], inplace=True)
df["label"] = pd.to_numeric(df["label"], errors='coerce')
df.dropna(subset=["label"], inplace=True)
df["label"] = df["label"].astype(int)
df["sequence"] = df["sequence"].str.lower()
df = df[df["sequence"].str.len() >= 6]

# Generate k-mers
def get_kmers(seq, k=6):
    return " ".join([seq[i:i+k] for i in range(len(seq)-k+1)])
df["kmers"] = df["sequence"].apply(get_kmers)

# Balance dataset
df_major = df[df["label"] == 0]
df_minor = df[df["label"] == 1]
df_minor_upsampled = resample(df_minor, replace=True, n_samples=len(df_major), random_state=42)
df_balanced = pd.concat([df_major, df_minor_upsampled]).sample(frac=1, random_state=42)

# TF-IDF Vectorization and binarization
vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(4, 6), max_features=20000)
X_sparse = vectorizer.fit_transform(df_balanced["kmers"])
X_binary = (X_sparse > 0).astype(int)
y = df_balanced["label"].values

# Train/test split
X_train, X_test, y_train, y_test = train_test_split(X_binary, y, stratify=y, test_size=0.2, random_state=42)

# Train Bernoulli Naive Bayes
model = BernoulliNB()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
y_probs = model.predict_proba(X_test)[:, 1]

# Evaluation
print("Accuracy:", round(accuracy_score(y_test, y_pred), 4))
print("\nClassification Report:\n", classification_report(y_test, y_pred, digits=4))

# Normalized Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
plt.figure(figsize=(6, 5))
sns.heatmap(cm_norm, annot=True, fmt=".2f", cmap="Greens", cbar=False,
            xticklabels=["Pred 0", "Pred 1"], yticklabels=["Actual 0", "Actual 1"])
plt.title("Confusion Matrix-Bernoulli Naive Bayes")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.savefig("normalized_confusion_matrix.png", dpi=300)
plt.show()

# ROC Curve
fpr, tpr, _ = roc_curve(y_test, y_probs)
roc_auc = auc(fpr, tpr)
plt.figure(figsize=(6, 5))
plt.plot(fpr, tpr, color='darkorange', label=f"ROC curve (AUC = {roc_auc:.4f})")
plt.plot([0, 1], [0, 1], linestyle='--', color='navy')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve - Bernoulli Naive Bayes")
plt.legend()
plt.tight_layout()
plt.savefig("roc_curve.png", dpi=300)
plt.show()

# Precision-Recall Curve
precision, recall, _ = precision_recall_curve(y_test, y_probs)
plt.figure(figsize=(6, 5))
plt.plot(recall, precision, color="purple")
plt.title("Precision-Recall Curve")
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.tight_layout()
plt.savefig("precision_recall_curve.png", dpi=300)
plt.show()

# Install packages
!pip install -q scikit-learn matplotlib seaborn

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import ComplementNB
from sklearn.utils import resample
from sklearn.metrics import (
    accuracy_score, classification_report, confusion_matrix,
    roc_curve, auc, precision_recall_curve
)

# Set seed
np.random.seed(42)

# Load dataset
df = pd.read_csv("merge-csv.com__683fc98d75a00.csv", names=["id", "sequence", "label"], skiprows=1)
df.dropna(subset=["sequence", "label"], inplace=True)
df["label"] = pd.to_numeric(df["label"], errors='coerce')
df.dropna(subset=["label"], inplace=True)
df["label"] = df["label"].astype(int)
df["sequence"] = df["sequence"].str.lower()
df = df[df["sequence"].str.len() >= 6]

# Generate k-mers
def get_kmers(seq, k=6):
    return " ".join([seq[i:i+k] for i in range(len(seq)-k+1)])
df["kmers"] = df["sequence"].apply(get_kmers)

# Balance dataset via upsampling
df_major = df[df["label"] == 0]
df_minor = df[df["label"] == 1]
df_minor_upsampled = resample(df_minor, replace=True, n_samples=len(df_major), random_state=42)
df_balanced = pd.concat([df_major, df_minor_upsampled]).sample(frac=1, random_state=42)

# TF-IDF Vectorization
vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(4, 6), max_features=20000)
X = vectorizer.fit_transform(df_balanced["kmers"])
y = df_balanced["label"].values

# Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)

# Train Complement Naive Bayes
model = ComplementNB()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
y_probs = model.predict_proba(X_test)[:, 1]

# Evaluation
print("Accuracy:", round(accuracy_score(y_test, y_pred), 4))
print("\nClassification Report:\n", classification_report(y_test, y_pred, digits=4))

# Normalized Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, cmap="Greens", cbar=False,
            xticklabels=["Pred 0", "Pred 1"], yticklabels=["Actual 0", "Actual 1"])
plt.title("Confusion Matrix-ComplementNB")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.savefig("normalized_confusion_matrix.png", dpi=300)
plt.show()

# ROC Curve
fpr, tpr, _ = roc_curve(y_test, y_probs)
roc_auc = auc(fpr, tpr)
plt.figure(figsize=(6, 5))
plt.plot(fpr, tpr, color='darkorange', label=f"ROC curve (AUC = {roc_auc:.4f})")
plt.plot([0, 1], [0, 1], linestyle='--', color='navy')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve - Complement Naive Bayes")
plt.legend()
plt.tight_layout()
plt.savefig("roc_curve.png", dpi=300)
plt.show()

# Precision-Recall Curve
precision, recall, _ = precision_recall_curve(y_test, y_probs)
plt.figure(figsize=(6, 5))
plt.plot(recall, precision, color="purple")
plt.title("Precision-Recall Curve-ComplementNB")
plt.xlabel("Recall")
plt.ylabel("Precision-Complement Naive Bayes")
plt.tight_layout()
plt.savefig("precision_recall_curve.png", dpi=300)
plt.show()

# Install packages
!pip install -q scikit-learn matplotlib seaborn

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.utils import resample
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import (
    accuracy_score, classification_report, confusion_matrix,
    roc_curve, auc, precision_recall_curve
)

# Set seed
np.random.seed(42)

# Load dataset
df = pd.read_csv("merge-csv.com__683fc98d75a00.csv", names=["id", "sequence", "label"], skiprows=1)
df.dropna(subset=["sequence", "label"], inplace=True)
df["label"] = pd.to_numeric(df["label"], errors='coerce')
df.dropna(subset=["label"], inplace=True)
df["label"] = df["label"].astype(int)
df["sequence"] = df["sequence"].str.lower()
df = df[df["sequence"].str.len() >= 6]

# Generate k-mers
def get_kmers(seq, k=6):
    return " ".join([seq[i:i+k] for i in range(len(seq)-k+1)])
df["kmers"] = df["sequence"].apply(get_kmers)

# Balance dataset via upsampling
df_major = df[df["label"] == 0]
df_minor = df[df["label"] == 1]
df_minor_upsampled = resample(df_minor, replace=True, n_samples=len(df_major), random_state=42)
df_balanced = pd.concat([df_major, df_minor_upsampled]).sample(frac=1, random_state=42)

# TF-IDF Vectorization (limited features for speed)
vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(4, 6), max_features=5000)
X = vectorizer.fit_transform(df_balanced["kmers"])
y = df_balanced["label"].values

# Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)

# Train Decision Tree Classifier
model = DecisionTreeClassifier(max_depth=20, class_weight="balanced", random_state=42)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
y_probs = model.predict_proba(X_test)[:, 1]

# Evaluation
print("Accuracy:", round(accuracy_score(y_test, y_pred), 4))
print("\nClassification Report:\n", classification_report(y_test, y_pred, digits=4))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
plt.figure(figsize=(6, 5))
sns.heatmap(cm_norm, annot=True, fmt=".2f", cmap="Greens", cbar=False,
            xticklabels=["Pred 0", "Pred 1"], yticklabels=["Actual 0", "Actual 1"])
plt.title("Normalized Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.savefig("dt_confusion_matrix.png", dpi=300)
plt.show()

# ROC Curve
fpr, tpr, _ = roc_curve(y_test, y_probs)
roc_auc = auc(fpr, tpr)
plt.figure(figsize=(6, 5))
plt.plot(fpr, tpr, color='darkorange', label=f"ROC curve (AUC = {roc_auc:.4f})")
plt.plot([0, 1], [0, 1], linestyle='--', color='navy')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve - Decision Tree")
plt.legend()
plt.tight_layout()
plt.savefig("dt_roc_curve.png", dpi=300)
plt.show()

# Precision-Recall Curve
precision, recall, _ = precision_recall_curve(y_test, y_probs)
plt.figure(figsize=(6, 5))
plt.plot(recall, precision, color="purple")
plt.title("Precision-Recall Curve")
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.tight_layout()
plt.savefig("dt_precision_recall_curve.png", dpi=300)
plt.show()



# Install packages
!pip install -q scikit-learn matplotlib seaborn

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.utils import resample
from sklearn.svm import LinearSVC
from sklearn.metrics import (
    accuracy_score, classification_report, confusion_matrix,
    roc_curve, auc, precision_recall_curve
)

# Set seed
np.random.seed(42)

# Load dataset
df = pd.read_csv("merge-csv.com__683fc98d75a00.csv", names=["id", "sequence", "label"], skiprows=1)
df.dropna(subset=["sequence", "label"], inplace=True)
df["label"] = pd.to_numeric(df["label"], errors='coerce')
df.dropna(subset=["label"], inplace=True)
df["label"] = df["label"].astype(int)
df["sequence"] = df["sequence"].str.lower()
df = df[df["sequence"].str.len() >= 6]

# Generate k-mers
def get_kmers(seq, k=6):
    return " ".join([seq[i:i+k] for i in range(len(seq)-k+1)])
df["kmers"] = df["sequence"].apply(get_kmers)

# Balance dataset
df_major = df[df["label"] == 0]
df_minor = df[df["label"] == 1]
df_minor_upsampled = resample(df_minor, replace=True, n_samples=len(df_major), random_state=42)
df_balanced = pd.concat([df_major, df_minor_upsampled]).sample(frac=1, random_state=42)

# TF-IDF with reduced features
vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(4, 6), max_features=5000)
X = vectorizer.fit_transform(df_balanced["kmers"])
y = df_balanced["label"].values

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)

# Train Linear SVM (fast)
model = LinearSVC(class_weight='balanced', max_iter=1000, random_state=42)
model.fit(X_train, y_train)

# Predict
y_pred = model.predict(X_test)
y_scores = model.decision_function(X_test)  # For ROC and PR curves

# Accuracy & Report
print("Accuracy:", round(accuracy_score(y_test, y_pred), 4))
print("\nClassification Report:\n", classification_report(y_test, y_pred, digits=4))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
plt.figure(figsize=(6, 5))
sns.heatmap(cm_norm, annot=True, fmt=".2f", cmap="Greens", cbar=False,
            xticklabels=["Pred 0", "Pred 1"], yticklabels=["Actual 0", "Actual 1"])
plt.title("Confusion Matrix-Linear svc")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.savefig("normalized_confusion_matrix.png", dpi=300)
plt.show()

# ROC Curve
fpr, tpr, _ = roc_curve(y_test, y_scores)
roc_auc = auc(fpr, tpr)
plt.figure(figsize=(6, 5))
plt.plot(fpr, tpr, color='darkorange', label=f"ROC curve (AUC = {roc_auc:.4f})")
plt.plot([0, 1], [0, 1], linestyle='--', color='navy')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve - LinearSVC")
plt.legend()
plt.tight_layout()
plt.savefig("roc_curve.png", dpi=300)
plt.show()

# Precision-Recall Curve
precision, recall, _ = precision_recall_curve(y_test, y_scores)
plt.figure(figsize=(6, 5))
plt.plot(recall, precision, color="purple")
plt.title("Precision-Recall Curve")
plt.xlabel("Recall")
plt.ylabel("Precision-linearsvc")
plt.tight_layout()
plt.savefig("precision_recall_curve.png", dpi=300)
plt.show()



# Install packages
!pip install -q scikit-learn matplotlib seaborn

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.utils import resample
from sklearn.ensemble import ExtraTreesClassifier
from sklearn.metrics import (
    accuracy_score, classification_report, confusion_matrix,
    roc_curve, auc, precision_recall_curve
)

# Set seed
np.random.seed(42)

# Load dataset
df = pd.read_csv("merge-csv.com__683fc98d75a00.csv", names=["id", "sequence", "label"], skiprows=1)
df.dropna(subset=["sequence", "label"], inplace=True)
df["label"] = pd.to_numeric(df["label"], errors='coerce')
df.dropna(subset=["label"], inplace=True)
df["label"] = df["label"].astype(int)
df["sequence"] = df["sequence"].str.lower()
df = df[df["sequence"].str.len() >= 6]

# Generate k-mers
def get_kmers(seq, k=6):
    return " ".join([seq[i:i+k] for i in range(len(seq)-k+1)])
df["kmers"] = df["sequence"].apply(get_kmers)

# Balance dataset via upsampling
df_major = df[df["label"] == 0]
df_minor = df[df["label"] == 1]
df_minor_upsampled = resample(df_minor, replace=True, n_samples=len(df_major), random_state=42)
df_balanced = pd.concat([df_major, df_minor_upsampled]).sample(frac=1, random_state=42)

# TF-IDF Vectorization
vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(4, 6), max_features=5000)
X = vectorizer.fit_transform(df_balanced["kmers"])
y = df_balanced["label"].values

# Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)

# Train Extra Trees Classifier
model = ExtraTreesClassifier(n_estimators=100, max_depth=30, class_weight='balanced', random_state=42, n_jobs=-1)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
y_probs = model.predict_proba(X_test)[:, 1]

# Evaluation
print("Accuracy:", round(accuracy_score(y_test, y_pred), 4))
print("\nClassification Report:\n", classification_report(y_test, y_pred, digits=4))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, cmap="Greens", cbar=False,
            xticklabels=["Pred 0", "Pred 1"], yticklabels=["Actual 0", "Actual 1"])
plt.title("Confusion Matrix-extra tree classifier")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.savefig("et_confusion_matrix.png", dpi=300)
plt.show()

# ROC Curve
fpr, tpr, _ = roc_curve(y_test, y_probs)
roc_auc = auc(fpr, tpr)
plt.figure(figsize=(6, 5))
plt.plot(fpr, tpr, color='darkorange', label=f"ROC curve (AUC = {roc_auc:.4f})")
plt.plot([0, 1], [0, 1], linestyle='--', color='navy')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve - Extra Trees")
plt.legend()
plt.tight_layout()
plt.savefig("et_roc_curve.png", dpi=300)
plt.show()

# Precision-Recall Curve
precision, recall, _ = precision_recall_curve(y_test, y_probs)
plt.figure(figsize=(6, 5))
plt.plot(recall, precision, color="purple")
plt.title("Precision-Recall Curve-extra tree classifier")
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.tight_layout()
plt.savefig("et_precision_recall_curve.png", dpi=300)
plt.show()



# Install packages
!pip install -q scikit-learn matplotlib seaborn

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.neighbors import RadiusNeighborsClassifier
from sklearn.utils import resample
from sklearn.metrics import (
    accuracy_score, classification_report, confusion_matrix,
    roc_curve, auc, precision_recall_curve
)

# Set seed
np.random.seed(42)

# Load dataset
df = pd.read_csv("merge-csv.com__683fc98d75a00.csv", names=["id", "sequence", "label"], skiprows=1)
df.dropna(subset=["sequence", "label"], inplace=True)
df["label"] = pd.to_numeric(df["label"], errors='coerce')
df.dropna(subset=["label"], inplace=True)
df["label"] = df["label"].astype(int)
df["sequence"] = df["sequence"].str.lower()
df = df[df["sequence"].str.len() >= 6]

# Generate k-mers
def get_kmers(seq, k=6):
    return " ".join([seq[i:i+k] for i in range(len(seq)-k+1)])
df["kmers"] = df["sequence"].apply(get_kmers)

# Balance dataset via upsampling
df_major = df[df["label"] == 0]
df_minor = df[df["label"] == 1]
df_minor_upsampled = resample(df_minor, replace=True, n_samples=len(df_major), random_state=42)
df_balanced = pd.concat([df_major, df_minor_upsampled]).sample(frac=1, random_state=42)

# Reduce sample size for performance (optional)
df_balanced = df_balanced.sample(n=3000, random_state=42)

# TF-IDF Vectorization
vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(4, 6), max_features=10000)
X = vectorizer.fit_transform(df_balanced["kmers"]).toarray()
y = df_balanced["label"].values

# Split into train/test
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)

# Train Radius Neighbors Classifier
model = RadiusNeighborsClassifier(radius=1.0, weights='distance', outlier_label=0)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

# Estimate probabilities manually and handle missing neighbors
y_probs = []
for x in X_test:
    neighbors_idx = model.radius_neighbors([x], return_distance=False)[0]
    if len(neighbors_idx) == 0:
        y_probs.append(0.0)  # fallback if no neighbors found
    else:
        y_probs.append(np.mean(y_train[neighbors_idx]))
y_probs = np.array(y_probs)

# Evaluation
print("Accuracy:", round(accuracy_score(y_test, y_pred), 4))
print("\nClassification Report:\n", classification_report(y_test, y_pred, digits=4))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
plt.figure(figsize=(6, 5))
sns.heatmap(cm_norm, annot=True, fmt=".2f", cmap="Greens", cbar=False,
            xticklabels=["Pred 0", "Pred 1"], yticklabels=["Actual 0", "Actual 1"])
plt.title("Normalized Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.savefig("normalized_confusion_matrix.png", dpi=300)
plt.show()

# ROC Curve
fpr, tpr, _ = roc_curve(y_test, y_probs)
roc_auc = auc(fpr, tpr)
plt.figure(figsize=(6, 5))
plt.plot(fpr, tpr, color='darkorange', label=f"ROC curve (AUC = {roc_auc:.4f})")
plt.plot([0, 1], [0, 1], linestyle='--', color='navy')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve - Radius Neighbors")
plt.legend()
plt.tight_layout()
plt.savefig("roc_curve.png", dpi=300)
plt.show()

# Precision-Recall Curve
precision, recall, _ = precision_recall_curve(y_test, y_probs)
plt.figure(figsize=(6, 5))
plt.plot(recall, precision, color="purple")
plt.title("Precision-Recall Curve")
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.tight_layout()
plt.savefig("precision_recall_curve.png", dpi=300)
plt.show()



# Install packages (only needed the first time)
!pip install -q scikit-learn matplotlib seaborn catboost

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.utils import resample
from sklearn.metrics import (
    accuracy_score, classification_report, confusion_matrix,
    roc_curve, auc, precision_recall_curve, f1_score
)
from catboost import CatBoostClassifier

# Set seed
np.random.seed(42)

# Load dataset
df = pd.read_csv("merge-csv.com__683fc98d75a00.csv", names=["id", "sequence", "label"], skiprows=1)
df.dropna(subset=["sequence", "label"], inplace=True)
df["label"] = pd.to_numeric(df["label"], errors='coerce')
df.dropna(subset=["label"], inplace=True)
df["label"] = df["label"].astype(int)
df["sequence"] = df["sequence"].str.lower()
df = df[df["sequence"].str.len() >= 6]

# Generate k-mers
def get_kmers(seq, k=6):
    return " ".join([seq[i:i+k] for i in range(len(seq)-k+1)])
df["kmers"] = df["sequence"].apply(get_kmers)

# Balance dataset via upsampling
df_major = df[df["label"] == 0]
df_minor = df[df["label"] == 1]
df_minor_upsampled = resample(df_minor, replace=True, n_samples=len(df_major), random_state=42)
df_balanced = pd.concat([df_major, df_minor_upsampled]).sample(frac=1, random_state=42)

# TF-IDF Vectorization
vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(4, 6), max_features=10000)
X = vectorizer.fit_transform(df_balanced["kmers"])
y = df_balanced["label"].values

# Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)

# CatBoost does not support sparse matrices directly; convert to dense
X_train_dense = X_train.toarray()
X_test_dense = X_test.toarray()

# Train CatBoost
model = CatBoostClassifier(
    iterations=300,
    learning_rate=0.05,
    depth=6,
    eval_metric='F1',
    verbose=0,
    random_seed=42,
    class_weights=[1, 1]  # Set manually or use 'Balanced' for automatic
)
model.fit(X_train_dense, y_train)

# Predict
y_probs = model.predict_proba(X_test_dense)[:, 1]
y_pred = (y_probs >= 0.5).astype(int)

# Evaluation
print("CatBoost Accuracy:", round(accuracy_score(y_test, y_pred), 4))
print("\nClassification Report:\n", classification_report(y_test, y_pred, digits=4))

# Normalized Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
plt.figure(figsize=(6, 5))
sns.heatmap(cm_norm, annot=True, fmt=".2f", cmap="Greens", cbar=False,
            xticklabels=["Pred 0", "Pred 1"], yticklabels=["Actual 0", "Actual 1"])
plt.title("Normalized Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.savefig("normalized_confusion_matrix.png", dpi=300)
plt.show()

# ROC Curve
fpr, tpr, _ = roc_curve(y_test, y_probs)
roc_auc = auc(fpr, tpr)
plt.figure(figsize=(6, 5))
plt.plot(fpr, tpr, color='darkorange', label=f"ROC curve (AUC = {roc_auc:.4f})")
plt.plot([0, 1], [0, 1], linestyle='--', color='navy')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve - CatBoost")
plt.legend()
plt.tight_layout()
plt.savefig("roc_curve.png", dpi=300)
plt.show()

# Precision-Recall Curve
precision, recall, _ = precision_recall_curve(y_test, y_probs)
plt.figure(figsize=(6, 5))
plt.plot(recall, precision, color="purple")
plt.title("Precision-Recall Curve")
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.tight_layout()
plt.savefig("precision_recall_curve.png", dpi=300)
plt.show()

# Install packages
!pip install -q scikit-learn matplotlib seaborn

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import Perceptron
from sklearn.utils import resample
from sklearn.metrics import (
    accuracy_score, classification_report, confusion_matrix,
    roc_curve, auc, precision_recall_curve, f1_score
)

# Set seed
np.random.seed(42)

# Load dataset
df = pd.read_csv("merge-csv.com__683fc98d75a00.csv", names=["id", "sequence", "label"], skiprows=1)
df.dropna(subset=["sequence", "label"], inplace=True)
df["label"] = pd.to_numeric(df["label"], errors='coerce')
df.dropna(subset=["label"], inplace=True)
df["label"] = df["label"].astype(int)
df["sequence"] = df["sequence"].str.lower()
df = df[df["sequence"].str.len() >= 6]

# Generate k-mers
def get_kmers(seq, k=6):
    return " ".join([seq[i:i+k] for i in range(len(seq)-k+1)])
df["kmers"] = df["sequence"].apply(get_kmers)

# Balance dataset via upsampling
df_major = df[df["label"] == 0]
df_minor = df[df["label"] == 1]
df_minor_upsampled = resample(df_minor, replace=True, n_samples=len(df_major), random_state=42)
df_balanced = pd.concat([df_major, df_minor_upsampled]).sample(frac=1, random_state=42)

# TF-IDF Vectorization
vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(4, 6), max_features=10000)
X = vectorizer.fit_transform(df_balanced["kmers"])
y = df_balanced["label"].values

# Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)

# Train Perceptron model
model = Perceptron(max_iter=1000, tol=1e-3, random_state=42)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

# No probabilities from Perceptron, use decision_function for ROC/PR curves
y_scores = model.decision_function(X_test)

# Evaluation
print("Perceptron Accuracy:", round(accuracy_score(y_test, y_pred), 4))
print("\nClassification Report:\n", classification_report(y_test, y_pred, digits=4))

# Normalized Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
plt.figure(figsize=(6, 5))
sns.heatmap(cm_norm, annot=True, fmt=".2f", cmap="Greens", cbar=False,
            xticklabels=["Pred 0", "Pred 1"], yticklabels=["Actual 0", "Actual 1"])
plt.title("Normalized Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.savefig("normalized_confusion_matrix.png", dpi=300)
plt.show()

# ROC Curve
fpr, tpr, _ = roc_curve(y_test, y_scores)
roc_auc = auc(fpr, tpr)
plt.figure(figsize=(6, 5))
plt.plot(fpr, tpr, color='darkorange', label=f"ROC curve (AUC = {roc_auc:.4f})")
plt.plot([0, 1], [0, 1], linestyle='--', color='navy')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve - Perceptron")
plt.legend()
plt.tight_layout()
plt.savefig("roc_curve.png", dpi=300)
plt.show()

# Precision-Recall Curve
precision, recall, _ = precision_recall_curve(y_test, y_scores)
plt.figure(figsize=(6, 5))
plt.plot(recall, precision, color="purple")
plt.title("Precision-Recall Curve")
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.tight_layout()
plt.savefig("precision_recall_curve.png", dpi=300)
plt.show()

# Install packages
!pip install -q scikit-learn matplotlib seaborn

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.utils import resample
from sklearn.metrics import (
    accuracy_score, classification_report, confusion_matrix,
    roc_curve, auc, precision_recall_curve, f1_score
)

# Set seed
np.random.seed(42)

# Load dataset
df = pd.read_csv("merge-csv.com__683fc98d75a00.csv", names=["id", "sequence", "label"], skiprows=1)
df.dropna(subset=["sequence", "label"], inplace=True)
df["label"] = pd.to_numeric(df["label"], errors='coerce')
df.dropna(subset=["label"], inplace=True)
df["label"] = df["label"].astype(int)
df["sequence"] = df["sequence"].str.lower()
df = df[df["sequence"].str.len() >= 6]

# Subsample data to prevent memory crash (e.g., 10,000 rows)
#df = df.sample(n=40000, random_state=42)

# Generate k-mers
def get_kmers(seq, k=6):
    return " ".join([seq[i:i+k] for i in range(len(seq) - k + 1)])
df["kmers"] = df["sequence"].apply(get_kmers)

# Balance dataset via upsampling
df_major = df[df["label"] == 0]
df_minor = df[df["label"] == 1]
df_minor_upsampled = resample(df_minor, replace=True, n_samples=len(df_major), random_state=42)
df_balanced = pd.concat([df_major, df_minor_upsampled]).sample(frac=1, random_state=42)

# Reduce TF-IDF size to avoid crash
vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(4, 6), max_features=2000)
X_sparse = vectorizer.fit_transform(df_balanced["kmers"])
X = X_sparse.toarray()  # GaussianNB needs dense input
y = df_balanced["label"].values

# Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)

# Train Gaussian Naive Bayes
model = GaussianNB()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
y_probs = model.predict_proba(X_test)[:, 1]

# Evaluation
print("GaussianNB Accuracy:", round(accuracy_score(y_test, y_pred), 4))
print("\nClassification Report:\n", classification_report(y_test, y_pred, digits=4))

# Normalized Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
plt.figure(figsize=(6, 5))
sns.heatmap(cm_norm, annot=True, fmt=".2f", cmap="Greens", cbar=False,
            xticklabels=["Pred 0", "Pred 1"], yticklabels=["Actual 0", "Actual 1"])
plt.title("Normalized Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.savefig("normalized_confusion_matrix.png", dpi=300)
plt.show()

# ROC Curve
fpr, tpr, _ = roc_curve(y_test, y_probs)
roc_auc = auc(fpr, tpr)
plt.figure(figsize=(6, 5))
plt.plot(fpr, tpr, color='darkorange', label=f"ROC curve (AUC = {roc_auc:.4f})")
plt.plot([0, 1], [0, 1], linestyle='--', color='navy')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve - GaussianNB")
plt.legend()
plt.tight_layout()
plt.savefig("roc_curve.png", dpi=300)
plt.show()

# Precision-Recall Curve
precision, recall, _ = precision_recall_curve(y_test, y_probs)
plt.figure(figsize=(6, 5))
plt.plot(recall, precision, color="purple")
plt.title("Precision-Recall Curve")
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.tight_layout()
plt.savefig("precision_recall_curve.png", dpi=300)
plt.show()

# Install packages
!pip install -q scikit-learn matplotlib seaborn

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.ensemble import BaggingClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.utils import resample
from sklearn.metrics import (
    accuracy_score, classification_report, confusion_matrix,
    roc_curve, auc, precision_recall_curve, f1_score
)

# Set seed
np.random.seed(42)

# Load dataset
df = pd.read_csv("merge-csv.com__683fc98d75a00.csv", names=["id", "sequence", "label"], skiprows=1)
df.dropna(subset=["sequence", "label"], inplace=True)
df["label"] = pd.to_numeric(df["label"], errors='coerce')
df.dropna(subset=["label"], inplace=True)
df["label"] = df["label"].astype(int)
df["sequence"] = df["sequence"].str.lower()
df = df[df["sequence"].str.len() >= 6]

# Subsample for memory efficiency (optional)
#df = df.sample(n=30000, random_state=42)

# Generate k-mers
def get_kmers(seq, k=6):
    return " ".join([seq[i:i+k] for i in range(len(seq) - k + 1)])
df["kmers"] = df["sequence"].apply(get_kmers)

# Balance dataset via upsampling
df_major = df[df["label"] == 0]
df_minor = df[df["label"] == 1]
df_minor_upsampled = resample(df_minor, replace=True, n_samples=len(df_major), random_state=42)
df_balanced = pd.concat([df_major, df_minor_upsampled]).sample(frac=1, random_state=42)

# TF-IDF Vectorization (keep sparse)
vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(4, 6), max_features=5000)
X = vectorizer.fit_transform(df_balanced["kmers"])
y = df_balanced["label"].values

# Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)

# Train Bagging Classifier with Decision Tree base
model = BaggingClassifier(
    estimator=DecisionTreeClassifier(),
    n_estimators=100,
    max_samples=0.8,
    max_features=0.8,
    bootstrap=True,
    random_state=42,
    n_jobs=-1
)
model.fit(X_train, y_train)

# Predict
y_pred = model.predict(X_test)
y_probs = model.predict_proba(X_test)[:, 1]

# Evaluation
print("BaggingClassifier Accuracy:", round(accuracy_score(y_test, y_pred), 4))
print("\nClassification Report:\n", classification_report(y_test, y_pred, digits=4))

# Normalized Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
plt.figure(figsize=(6, 5))
sns.heatmap(cm_norm, annot=True, fmt=".2f", cmap="Greens", cbar=False,
            xticklabels=["Pred 0", "Pred 1"], yticklabels=["Actual 0", "Actual 1"])
plt.title("Normalized Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.savefig("normalized_confusion_matrix.png", dpi=300)
plt.show()

# ROC Curve
fpr, tpr, _ = roc_curve(y_test, y_probs)
roc_auc = auc(fpr, tpr)
plt.figure(figsize=(6, 5))
plt.plot(fpr, tpr, color='darkorange', label=f"ROC curve (AUC = {roc_auc:.4f})")
plt.plot([0, 1], [0, 1], linestyle='--', color='navy')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve - BaggingClassifier")
plt.legend()
plt.tight_layout()
plt.savefig("roc_curve.png", dpi=300)
plt.show()

# Precision-Recall Curve
precision, recall, _ = precision_recall_curve(y_test, y_probs)
plt.figure(figsize=(6, 5))
plt.plot(recall, precision, color="purple")
plt.title("Precision-Recall Curve")
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.tight_layout()
plt.savefig("precision_recall_curve.png", dpi=300)
plt.show()



# ✅ Install required libraries (for Colab or fresh environments)
!pip install -q scikit-learn matplotlib seaborn

# ✅ Import Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import BaggingClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.utils import resample
from sklearn.metrics import (
    accuracy_score, classification_report, confusion_matrix,
    roc_curve, auc, precision_recall_curve
)

# ✅ Set random seed
np.random.seed(42)

# ✅ Load dataset
df = pd.read_csv("merge-csv.com__683fc98d75a00.csv", names=["id", "sequence", "label"], skiprows=1)
df.dropna(subset=["sequence", "label"], inplace=True)
df["label"] = pd.to_numeric(df["label"], errors='coerce')
df.dropna(subset=["label"], inplace=True)
df["label"] = df["label"].astype(int)
df["sequence"] = df["sequence"].str.lower()
df = df[df["sequence"].str.len() >= 6]

# ✅ Generate 6-mers
def get_kmers(seq, k=6):
    return " ".join([seq[i:i+k] for i in range(len(seq) - k + 1)])
df["kmers"] = df["sequence"].apply(get_kmers)

# ✅ Balance dataset by upsampling minority class
df_major = df[df["label"] == 0]
df_minor = df[df["label"] == 1]
df_minor_upsampled = resample(df_minor, replace=True, n_samples=len(df_major), random_state=42)
df_balanced = pd.concat([df_major, df_minor_upsampled]).sample(frac=1, random_state=42)

# ✅ Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    df_balanced["kmers"], df_balanced["label"], stratify=df_balanced["label"], test_size=0.2, random_state=42
)

# ✅ Build pipeline (TF-IDF + Bagging with DecisionTree)
pipeline = Pipeline([
    ('tfidf', TfidfVectorizer(analyzer='word', ngram_range=(4, 6), max_features=5000)),
    ('bagging', BaggingClassifier(
        estimator=DecisionTreeClassifier(max_depth=None, class_weight='balanced'),
        n_estimators=100,
        random_state=42,
        n_jobs=-1
    ))
])

# ✅ Train model
pipeline.fit(X_train, y_train)

# ✅ Predict
y_pred = pipeline.predict(X_test)
y_probs = pipeline.predict_proba(X_test)[:, 1]

# ✅ Evaluation
print("\n🎯 Accuracy:", round(accuracy_score(y_test, y_pred), 4))
print("\n🧾 Classification Report:\n", classification_report(y_test, y_pred, digits=4))

# ✅ Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
plt.figure(figsize=(6, 5))
sns.heatmap(cm_norm, annot=True, fmt=".2f", cmap="Greens", cbar=False,
            xticklabels=["Pred 0", "Pred 1"], yticklabels=["Actual 0", "Actual 1"])
plt.title("Normalized Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.savefig("normalized_confusion_matrix.png", dpi=300)
plt.show()

# ✅ ROC Curve
fpr, tpr, _ = roc_curve(y_test, y_probs)
roc_auc = auc(fpr, tpr)
plt.figure(figsize=(6, 5))
plt.plot(fpr, tpr, color='darkorange', label=f"ROC curve (AUC = {roc_auc:.4f})")
plt.plot([0, 1], [0, 1], linestyle='--', color='navy')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve")
plt.legend()
plt.grid()
plt.tight_layout()
plt.savefig("roc_curve.png", dpi=300)
plt.show()

# ✅ Precision-Recall Curve
precision, recall, _ = precision_recall_curve(y_test, y_probs)
plt.figure(figsize=(6, 5))
plt.plot(recall, precision, color="purple")
plt.title("Precision-Recall Curve")
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.grid()
plt.tight_layout()
plt.savefig("precision_recall_curve.png", dpi=300)
plt.show()



# ✅ Install required packages (if in Colab or fresh env)
!pip install -q scikit-learn matplotlib seaborn

# ✅ Import libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.utils import resample
from sklearn.metrics import (
    accuracy_score, classification_report, confusion_matrix,
    roc_curve, auc, precision_recall_curve
)

from sklearn.naive_bayes import MultinomialNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import StackingClassifier

# ✅ Set seed
np.random.seed(42)

# ✅ Load and clean data
df = pd.read_csv("merge-csv.com__683fc98d75a00.csv", names=["id", "sequence", "label"], skiprows=1)
df.dropna(subset=["sequence", "label"], inplace=True)
df["label"] = pd.to_numeric(df["label"], errors='coerce')
df.dropna(subset=["label"], inplace=True)
df["label"] = df["label"].astype(int)
df["sequence"] = df["sequence"].str.lower()
df = df[df["sequence"].str.contains("^[acgt]+$", regex=True)]
df = df[df["sequence"].str.len() >= 6]

# ✅ Generate 6-mers
def get_kmers(seq, k=6):
    return " ".join([seq[i:i+k] for i in range(len(seq) - k + 1)])
df["kmers"] = df["sequence"].apply(get_kmers)

# ✅ Balance classes by upsampling minority class
df_major = df[df["label"] == 0]
df_minor = df[df["label"] == 1]
df_minor_upsampled = resample(df_minor, replace=True, n_samples=len(df_major), random_state=42)
df_balanced = pd.concat([df_major, df_minor_upsampled]).sample(frac=1, random_state=42)

# ✅ Optional: Subsample to reduce memory use
df_balanced = df_balanced.sample(n=20000, random_state=42)

# ✅ Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    df_balanced["kmers"], df_balanced["label"],
    stratify=df_balanced["label"], test_size=0.2, random_state=42
)

# ✅ TF-IDF vectorizer
vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(4, 6), max_features=2000)
X_train_vec = vectorizer.fit_transform(X_train)
X_test_vec = vectorizer.transform(X_test)

# ✅ Define base models and meta-learner
base_models = [
    ('nb', MultinomialNB(alpha=1.0)),
    ('knn', KNeighborsClassifier(n_neighbors=5))
]
meta_model = LogisticRegression(max_iter=500)

# ✅ Build stacking classifier
stack_model = StackingClassifier(
    estimators=base_models,
    final_estimator=meta_model,
    cv=3,
    n_jobs=1,  # prevent parallel crash
    passthrough=True
)

# ✅ Train model
stack_model.fit(X_train_vec, y_train)

# ✅ Predict
y_pred = stack_model.predict(X_test_vec)
y_probs = stack_model.predict_proba(X_test_vec)[:, 1]

# ✅ Evaluation metrics
print("\n🎯 Accuracy:", round(accuracy_score(y_test, y_pred), 4))
print("\n🧾 Classification Report:\n", classification_report(y_test, y_pred, digits=4))

# ✅ Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
plt.figure(figsize=(6, 5))
sns.heatmap(cm_norm, annot=True, fmt=".2f", cmap="Greens", cbar=False,
            xticklabels=["Pred 0", "Pred 1"], yticklabels=["Actual 0", "Actual 1"])
plt.title("Normalized Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.show()

# ✅ ROC Curve
fpr, tpr, _ = roc_curve(y_test, y_probs)
roc_auc = auc(fpr, tpr)
plt.figure(figsize=(6, 5))
plt.plot(fpr, tpr, color='darkorange', label=f"ROC curve (AUC = {roc_auc:.4f})")
plt.plot([0, 1], [0, 1], linestyle='--', color='navy')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve")
plt.legend()
plt.grid()
plt.tight_layout()
plt.show()

# ✅ Precision-Recall Curve
precision, recall, _ = precision_recall_curve(y_test, y_probs)
plt.figure(figsize=(6, 5))
plt.plot(recall, precision, color="purple")
plt.title("Precision-Recall Curve")
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.grid()
plt.tight_layout()
plt.show()

# ✅ Install required packages
!pip install -q scikit-learn matplotlib seaborn

# ✅ Import libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.utils import resample
from sklearn.metrics import (
    accuracy_score, classification_report, confusion_matrix,
    roc_curve, auc, precision_recall_curve
)

from sklearn.naive_bayes import MultinomialNB
from sklearn.ensemble import RandomForestClassifier, StackingClassifier
from sklearn.linear_model import LogisticRegression

# ✅ Set seed
np.random.seed(42)

# ✅ Load and clean data
df = pd.read_csv("merge-csv.com__683fc98d75a00.csv", names=["id", "sequence", "label"], skiprows=1)
df.dropna(subset=["sequence", "label"], inplace=True)
df["label"] = pd.to_numeric(df["label"], errors='coerce')
df.dropna(subset=["label"], inplace=True)
df["label"] = df["label"].astype(int)
df["sequence"] = df["sequence"].str.lower()
df = df[df["sequence"].str.contains("^[acgt]+$", regex=True)]
df = df[df["sequence"].str.len() >= 6]

# ✅ Generate 6-mers
def get_kmers(seq, k=6):
    return " ".join([seq[i:i+k] for i in range(len(seq) - k + 1)])
df["kmers"] = df["sequence"].apply(get_kmers)

# ✅ Downsample majority class
df_major = df[df["label"] == 0]
df_minor = df[df["label"] == 1]
df_major_down = resample(df_major, replace=False, n_samples=len(df_minor), random_state=42)
df_balanced = pd.concat([df_major_down, df_minor]).sample(frac=1, random_state=42)

# ✅ Optional: Subsample if more than 30000
if len(df_balanced) > 30000:
    df_balanced = df_balanced.sample(n=30000, random_state=42)

# ✅ Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    df_balanced["kmers"], df_balanced["label"],
    stratify=df_balanced["label"], test_size=0.2, random_state=42
)

# ✅ TF-IDF vectorizer (adjusted to avoid overfit)
vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(4, 6), max_features=2000)
X_train_vec = vectorizer.fit_transform(X_train)
X_test_vec = vectorizer.transform(X_test)

# ✅ Define base and meta models
base_models = [
    ('nb', MultinomialNB(alpha=0.5)),
    ('rf', RandomForestClassifier(n_estimators=50, max_depth=20, class_weight='balanced', random_state=42))
]
meta_model = LogisticRegression(max_iter=1000)

# ✅ Build stacking classifier
stack_model = StackingClassifier(
    estimators=base_models,
    final_estimator=meta_model,
    cv=3,
    n_jobs=1,
    passthrough=True
)

# ✅ Train model
stack_model.fit(X_train_vec, y_train)

# ✅ Predict
y_pred = stack_model.predict(X_test_vec)
y_probs = stack_model.predict_proba(X_test_vec)[:, 1]

# ✅ Evaluation
print("\n🎯 Accuracy:", round(accuracy_score(y_test, y_pred), 4))
print("\n🧾 Classification Report:\n", classification_report(y_test, y_pred, digits=4))

# ✅ Confusion Matrix (normalized)
cm = confusion_matrix(y_test, y_pred)
cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
plt.figure(figsize=(6, 5))
sns.heatmap(cm_norm, annot=True, fmt=".2f", cmap="Greens", cbar=False,
            xticklabels=["Pred 0", "Pred 1"], yticklabels=["Actual 0", "Actual 1"])
plt.title("Normalized Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.show()

# ✅ Show raw confusion matrix too
print("\n🧮 Raw Confusion Matrix:\n", cm)

# ✅ ROC Curve
fpr, tpr, _ = roc_curve(y_test, y_probs)
roc_auc = auc(fpr, tpr)
plt.figure(figsize=(6, 5))
plt.plot(fpr, tpr, color='darkorange', label=f"ROC curve (AUC = {roc_auc:.4f})")
plt.plot([0, 1], [0, 1], linestyle='--', color='navy')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve")
plt.legend()
plt.grid()
plt.tight_layout()
plt.show()

# ✅ Precision-Recall Curve
precision, recall, _ = precision_recall_curve(y_test, y_probs)
plt.figure(figsize=(6, 5))
plt.plot(recall, precision, color="purple")
plt.title("Precision-Recall Curve")
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.grid()
plt.tight_layout()
plt.show()

# ✅ Install required packages
!pip install -q scikit-learn matplotlib seaborn

# ✅ Import libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.utils import resample
from sklearn.metrics import (
    accuracy_score, classification_report, confusion_matrix,
    roc_curve, auc, precision_recall_curve
)

from sklearn.naive_bayes import MultinomialNB
from sklearn.ensemble import RandomForestClassifier, StackingClassifier
from sklearn.linear_model import LogisticRegression

# ✅ Set seed
np.random.seed(42)

# ✅ Load and clean data
df = pd.read_csv("merge-csv.com__683fc98d75a00.csv", names=["id", "sequence", "label"], skiprows=1)
df.dropna(subset=["sequence", "label"], inplace=True)
df["label"] = pd.to_numeric(df["label"], errors='coerce')
df.dropna(subset=["label"], inplace=True)
df["label"] = df["label"].astype(int)
df["sequence"] = df["sequence"].str.lower()
df = df[df["sequence"].str.contains("^[acgt]+$", regex=True)]
df = df[df["sequence"].str.len() >= 6]

# ✅ Generate 6-mers
def get_kmers(seq, k=6):
    return " ".join([seq[i:i+k] for i in range(len(seq) - k + 1)])
df["kmers"] = df["sequence"].apply(get_kmers)

# ✅ Upsample minority class (retain all data and balance it)
df_major = df[df["label"] == 0]
df_minor = df[df["label"] == 1]
df_minor_upsampled = resample(df_minor, replace=True, n_samples=len(df_major), random_state=42)
df_balanced = pd.concat([df_major, df_minor_upsampled]).sample(frac=1, random_state=42)

# ✅ Subsample if very large (optional)
if len(df_balanced) > 30000:
    df_balanced = df_balanced.sample(n=30000, random_state=42)

# ✅ Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    df_balanced["kmers"], df_balanced["label"],
    stratify=df_balanced["label"], test_size=0.2, random_state=42
)

# ✅ TF-IDF vectorizer (optimized for expressiveness)
vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(5, 7), max_features=5000)
X_train_vec = vectorizer.fit_transform(X_train)
X_test_vec = vectorizer.transform(X_test)

# ✅ Define base and meta models
base_models = [
    ('nb', MultinomialNB(alpha=0.1)),
    ('rf', RandomForestClassifier(n_estimators=100, max_depth=40, class_weight='balanced', random_state=42))
]
meta_model = LogisticRegression(max_iter=1000)

# ✅ Build stacking classifier
stack_model = StackingClassifier(
    estimators=base_models,
    final_estimator=meta_model,
    cv=3,
    n_jobs=1,
    passthrough=True
)

# ✅ Train model
stack_model.fit(X_train_vec, y_train)

# ✅ Predict
y_pred = stack_model.predict(X_test_vec)
y_probs = stack_model.predict_proba(X_test_vec)[:, 1]

# ✅ Evaluation
print("\n🎯 Accuracy:", round(accuracy_score(y_test, y_pred), 4))
print("\n🧾 Classification Report:\n", classification_report(y_test, y_pred, digits=4))

# ✅ Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
print("\n🧮 Confusion Matrix:\n", cm)

cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
plt.figure(figsize=(6, 5))
sns.heatmap(cm_norm, annot=True, fmt=".2f", cmap="Greens", cbar=False,
            xticklabels=["Pred 0", "Pred 1"], yticklabels=["Actual 0", "Actual 1"])
plt.title("Normalized Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.show()

# ✅ ROC Curve
fpr, tpr, _ = roc_curve(y_test, y_probs)
roc_auc = auc(fpr, tpr)
plt.figure(figsize=(6, 5))
plt.plot(fpr, tpr, color='darkorange', label=f"ROC curve (AUC = {roc_auc:.4f})")
plt.plot([0, 1], [0, 1], linestyle='--', color='navy')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve")
plt.legend()
plt.grid()
plt.tight_layout()
plt.show()

# ✅ Precision-Recall Curve
precision, recall, _ = precision_recall_curve(y_test, y_probs)
plt.figure(figsize=(6, 5))
plt.plot(recall, precision, color="purple")
plt.title("Precision-Recall Curve")
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.grid()
plt.tight_layout()
plt.show()

# ✅ Install packages
!pip install -q scikit-learn matplotlib seaborn

# ✅ Import libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.utils import resample
from sklearn.metrics import (
    accuracy_score, classification_report, confusion_matrix,
    roc_curve, auc, precision_recall_curve
)

from sklearn.ensemble import RandomForestClassifier, StackingClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression

# ✅ Set random seed
np.random.seed(42)

# ✅ Load dataset
df = pd.read_csv("merge-csv.com__683fc98d75a00.csv", names=["id", "sequence", "label"], skiprows=1)
df.dropna(subset=["sequence", "label"], inplace=True)
df["label"] = pd.to_numeric(df["label"], errors='coerce')
df.dropna(subset=["label"], inplace=True)
df["label"] = df["label"].astype(int)
df["sequence"] = df["sequence"].str.lower()
df = df[df["sequence"].str.contains("^[acgt]+$", regex=True)]
df = df[df["sequence"].str.len() >= 6]

# ✅ Generate 6-mers
def get_kmers(seq, k=6):
    return " ".join([seq[i:i+k] for i in range(len(seq) - k + 1)])
df["kmers"] = df["sequence"].apply(get_kmers)

# ✅ Upsample minority class
df_major = df[df["label"] == 0]
df_minor = df[df["label"] == 1]
df_minor_upsampled = resample(df_minor, replace=True, n_samples=len(df_major), random_state=42)
df_balanced = pd.concat([df_major, df_minor_upsampled]).sample(frac=1, random_state=42)

# ✅ Subsample slightly larger for more variety
df_balanced = df_balanced.sample(n=35000, random_state=42)

# ✅ Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    df_balanced["kmers"], df_balanced["label"],
    stratify=df_balanced["label"], test_size=0.2, random_state=42
)

# ✅ TF-IDF vectorizer (slightly more varied)
vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(5, 6), max_features=3000)
X_train_vec = vectorizer.fit_transform(X_train)
X_test_vec = vectorizer.transform(X_test)

# ✅ Define base and meta models (less overfitting)
base_models = [
    ('rf', RandomForestClassifier(n_estimators=50, max_depth=15, class_weight='balanced', random_state=42)),
    ('knn', KNeighborsClassifier(n_neighbors=5))
]
meta_model = LogisticRegression(max_iter=1000)

# ✅ Build stacking classifier
stack_model = StackingClassifier(
    estimators=base_models,
    final_estimator=meta_model,
    cv=3,
    n_jobs=1,
    passthrough=True
)

# ✅ Train model
stack_model.fit(X_train_vec, y_train)

# ✅ Predict
y_pred = stack_model.predict(X_test_vec)
y_probs = stack_model.predict_proba(X_test_vec)[:, 1]

# ✅ Evaluation
print("\n🎯 Accuracy:", round(accuracy_score(y_test, y_pred), 4))
print("\n🧾 Classification Report:\n", classification_report(y_test, y_pred, digits=4))

# ✅ Raw Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
print("\n🧮 Raw Confusion Matrix:\n", cm)

plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", cbar=False,
            xticklabels=["Pred 0", "Pred 1"], yticklabels=["Actual 0", "Actual 1"])
plt.title("Raw Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.show()

# ✅ ROC Curve
fpr, tpr, _ = roc_curve(y_test, y_probs)
roc_auc = auc(fpr, tpr)
plt.figure(figsize=(6, 5))
plt.plot(fpr, tpr, color='darkorange', label=f"ROC curve (AUC = {roc_auc:.4f})")
plt.plot([0, 1], [0, 1], linestyle='--', color='navy')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve")
plt.legend()
plt.grid()
plt.tight_layout()
plt.show()

# ✅ Precision-Recall Curve
precision, recall, _ = precision_recall_curve(y_test, y_probs)
plt.figure(figsize=(6, 5))
plt.plot(recall, precision, color="purple")
plt.title("Precision-Recall Curve")
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.grid()
plt.tight_layout()
plt.show()

# ✅ Install packages
!pip install -q scikit-learn matplotlib seaborn

# ✅ Import libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.utils import resample
from sklearn.metrics import (
    accuracy_score, classification_report, confusion_matrix,
    roc_curve, auc, precision_recall_curve
)

from sklearn.ensemble import RandomForestClassifier, StackingClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression

# ✅ Set random seed
np.random.seed(42)

# ✅ Load dataset
df = pd.read_csv("merge-csv.com__683fc98d75a00.csv", names=["id", "sequence", "label"], skiprows=1)
df.dropna(subset=["sequence", "label"], inplace=True)
df["label"] = pd.to_numeric(df["label"], errors='coerce')
df.dropna(subset=["label"], inplace=True)
df["label"] = df["label"].astype(int)
df["sequence"] = df["sequence"].str.lower()
df = df[df["sequence"].str.contains("^[acgt]+$", regex=True)]
df = df[df["sequence"].str.len() >= 6]

# ✅ Generate 6-mers
def get_kmers(seq, k=6):
    return " ".join([seq[i:i+k] for i in range(len(seq) - k + 1)])
df["kmers"] = df["sequence"].apply(get_kmers)

# ✅ Balance dataset (upsample minority class)
df_major = df[df["label"] == 0]
df_minor = df[df["label"] == 1]
df_minor_upsampled = resample(df_minor, replace=True, n_samples=len(df_major), random_state=42)
df_balanced = pd.concat([df_major, df_minor_upsampled]).sample(frac=1, random_state=42)

# ✅ Subsample to avoid overfitting
df_balanced = df_balanced.sample(n=20000, random_state=42)

# ✅ Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    df_balanced["kmers"], df_balanced["label"], stratify=df_balanced["label"], test_size=0.2, random_state=42
)

# ✅ TF-IDF vectorizer (less specific, less overfit)
vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(5, 6), max_features=10000)
X_train_vec = vectorizer.fit_transform(X_train)
X_test_vec = vectorizer.transform(X_test)

# ✅ Define base and meta models
base_models = [
    ('rf', RandomForestClassifier(n_estimators=50, max_depth=15, class_weight='balanced', random_state=42)),
    ('knn', KNeighborsClassifier(n_neighbors=5))
]
meta_model = LogisticRegression(max_iter=1000)

# ✅ Stacking Classifier
stack_model = StackingClassifier(
    estimators=base_models,
    final_estimator=meta_model,
    cv=3,
    n_jobs=1,
    passthrough=True
)

# ✅ Train model
stack_model.fit(X_train_vec, y_train)

# ✅ Predict
y_pred = stack_model.predict(X_test_vec)
y_probs = stack_model.predict_proba(X_test_vec)[:, 1]

# ✅ Evaluation
print("\n🎯 Accuracy:", round(accuracy_score(y_test, y_pred), 4))
print("\n🧾 Classification Report:\n", classification_report(y_test, y_pred, digits=4))

# ✅ Confusion Matrix (RAW, not normalized)
cm = confusion_matrix(y_test, y_pred)
print("\n🧮 Confusion Matrix:\n", cm)

plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", cbar=False,
            xticklabels=["Pred 0", "Pred 1"], yticklabels=["Actual 0", "Actual 1"])
plt.title("Confusion Matrix (Stacking Ensemble Model)")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.show()

# ✅ ROC Curve
fpr, tpr, _ = roc_curve(y_test, y_probs)
roc_auc = auc(fpr, tpr)
plt.figure(figsize=(6, 5))
plt.plot(fpr, tpr, color='darkorange', label=f"ROC curve (AUC = {roc_auc:.4f})")
plt.plot([0, 1], [0, 1], linestyle='--', color='navy')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve(Stacking Ensemble Model)")
plt.legend()
plt.grid()
plt.tight_layout()
plt.show()

# ✅ Precision-Recall Curve
precision, recall, _ = precision_recall_curve(y_test, y_probs)
plt.figure(figsize=(6, 5))
plt.plot(recall, precision, color="purple")
plt.title("Precision-Recall Curve(Stacking Ensemble Model) ")
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.grid()
plt.tight_layout()
plt.show()

# ✅ Install dependencies (if needed)
!pip install -q scikit-learn matplotlib seaborn

# ✅ Imports
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import re

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier, StackingClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression

# ✅ Set seed
np.random.seed(42)

# ✅ Load and clean data manually
df = pd.read_csv("merge-csv.com__683fc98d75a00.csv", names=["id", "sequence", "label"], skiprows=1)

# Remove nulls
df = df.dropna(subset=["sequence", "label"])
df["label"] = pd.to_numeric(df["label"], errors='coerce')
df = df.dropna(subset=["label"])
df["label"] = df["label"].astype(int)

# Lowercase and filter only valid ACGT sequences manually
def is_valid_dna(seq):
    return bool(re.fullmatch(r"[acgt]+", seq.lower()))

df = df[df["sequence"].apply(is_valid_dna)]
df["sequence"] = df["sequence"].apply(lambda x: x.lower())
df = df[df["sequence"].apply(lambda x: len(x) >= 6)]

# ✅ Generate 6-mers
def get_kmers(seq, k=6):
    return " ".join([seq[i:i+k] for i in range(len(seq) - k + 1)])
df["kmers"] = df["sequence"].apply(get_kmers)

# ✅ Manual upsampling
df_major = df[df["label"] == 0]
df_minor = df[df["label"] == 1]
df_minor_upsampled = df_minor.sample(n=len(df_major), replace=True, random_state=42)
df_balanced = pd.concat([df_major, df_minor_upsampled])

# ✅ Manual shuffle and subsample
df_balanced = df_balanced.sample(frac=1, random_state=42)
df_balanced = df_balanced.iloc[:20000].reset_index(drop=True)

# ✅ Manual train-test split (80/20)
split_index = int(len(df_balanced) * 0.8)
X = df_balanced["kmers"].values
y = df_balanced["label"].values
X_train_raw, X_test_raw = X[:split_index], X[split_index:]
y_train, y_test = y[:split_index], y[split_index:]

# ✅ TF-IDF vectorization (core ML)
vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(5, 6), max_features=2000)
X_train = vectorizer.fit_transform(X_train_raw)
X_test = vectorizer.transform(X_test_raw)

# ✅ Define ML models (core ML only)
base_models = [
    ("rf", RandomForestClassifier(n_estimators=50, max_depth=15, class_weight="balanced", random_state=42)),
    ("knn", KNeighborsClassifier(n_neighbors=5))
]
meta_model = LogisticRegression(max_iter=1000)

# ✅ Stacking classifier (core ML)
stack_model = StackingClassifier(
    estimators=base_models,
    final_estimator=meta_model,
    cv=3,
    passthrough=True,
    n_jobs=1
)

# ✅ Train
stack_model.fit(X_train, y_train)

# ✅ Predict
y_pred = stack_model.predict(X_test)
y_probs = stack_model.predict_proba(X_test)[:, 1]

# ✅ Manually evaluate
tp = sum((y_test == 1) & (y_pred == 1))
tn = sum((y_test == 0) & (y_pred == 0))
fp = sum((y_test == 0) & (y_pred == 1))
fn = sum((y_test == 1) & (y_pred == 0))

accuracy = (tp + tn) / len(y_test)
precision_1 = tp / (tp + fp) if (tp + fp) > 0 else 0
recall_1 = tp / (tp + fn) if (tp + fn) > 0 else 0
f1_1 = 2 * precision_1 * recall_1 / (precision_1 + recall_1) if (precision_1 + recall_1) > 0 else 0

print(f"\n🎯 Accuracy: {accuracy:.4f}")
print(f"\n🧾 Class 1 Metrics: Precision: {precision_1:.4f}, Recall: {recall_1:.4f}, F1: {f1_1:.4f}")
print(f"🧮 Confusion Matrix:\n[[TN: {tn}, FP: {fp}]\n [FN: {fn}, TP: {tp}]]")

# ✅ Plot Confusion Matrix
plt.figure(figsize=(6, 5))
sns.heatmap([[tn, fp], [fn, tp]], annot=True, fmt="d", cmap="Blues", cbar=False,
            xticklabels=["Pred 0", "Pred 1"], yticklabels=["Actual 0", "Actual 1"])
plt.title("Confusion Matrix (Counts)")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.show()

# ✅ ROC + PR Curves (minimal)
from sklearn.metrics import roc_curve, auc, precision_recall_curve

fpr, tpr, _ = roc_curve(y_test, y_probs)
roc_auc = auc(fpr, tpr)
plt.figure(figsize=(6, 5))
plt.plot(fpr, tpr, label=f"AUC = {roc_auc:.4f}")
plt.plot([0, 1], [0, 1], 'k--')
plt.title("ROC Curve")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend()
plt.grid()
plt.tight_layout()
plt.show()

precision, recall, _ = precision_recall_curve(y_test, y_probs)
plt.figure(figsize=(6, 5))
plt.plot(recall, precision, color="purple")
plt.title("Precision-Recall Curve")
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.grid()
plt.tight_layout()
plt.show()



# ✅ Fully Manual ML Pipeline (No Sklearn Models Used)
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import re
from collections import defaultdict, Counter
import math

# ✅ Set seed
np.random.seed(42)

# ✅ Load dataset
# (Make sure 'merge-csv.com__683fc98d75a00.csv' is present in your working directory)
df = pd.read_csv("merge-csv.com__683fc98d75a00.csv", names=["id", "sequence", "label"], skiprows=1)

# ✅ Clean dataset manually
df.dropna(subset=["sequence", "label"], inplace=True)
df["label"] = pd.to_numeric(df["label"], errors='coerce')
df.dropna(subset=["label"], inplace=True)
df["label"] = df["label"].astype(int)
df = df[df["sequence"].apply(lambda x: bool(re.fullmatch(r"[acgt]+", x.lower())))]
df["sequence"] = df["sequence"].str.lower()
df = df[df["sequence"].apply(lambda x: len(x) >= 6)]

# ✅ Generate 6-mers
def get_kmers(seq, k=6):
    return " ".join([seq[i:i+k] for i in range(len(seq) - k + 1)])
df["kmers"] = df["sequence"].apply(get_kmers)

# ✅ Balance dataset manually
df_major = df[df["label"] == 0]
df_minor = df[df["label"] == 1]
df_minor_upsampled = df_minor.sample(n=len(df_major), replace=True, random_state=42)
df_balanced = pd.concat([df_major, df_minor_upsampled]).sample(frac=1, random_state=42).reset_index(drop=True)
df_balanced = df_balanced.iloc[:20000]  # subsample to 20000 rows

# ✅ Manual train-test split
split_index = int(len(df_balanced) * 0.8)
X = df_balanced["kmers"].values
y = df_balanced["label"].values
X_train_raw, X_test_raw = X[:split_index], X[split_index:]
y_train, y_test = y[:split_index], y[split_index:]

# ✅ Manual TF-IDF
def extract_kmers(seq, ks=(5, 6)):
    tokens = []
    for k in ks:
        tokens.extend([seq[i:i+k] for i in range(len(seq) - k + 1)])
    return tokens

all_docs = list(X_train_raw) + list(X_test_raw)
tokenized_docs = [extract_kmers(seq) for seq in all_docs]
doc_count = len(tokenized_docs)
df_counter = defaultdict(int)
for tokens in tokenized_docs:
    for token in set(tokens):
        df_counter[token] += 1

# Top 2000 tokens
top_kmers = sorted(df_counter.items(), key=lambda x: -x[1])[:2000]
vocab = {token: idx for idx, (token, _) in enumerate(top_kmers)}

def compute_tfidf(tokens, vocab, df_counter, N):
    tf = Counter(tokens)
    vector = np.zeros(len(vocab))
    for token, count in tf.items():
        if token in vocab:
            tf_val = count
            idf_val = math.log(N / (1 + df_counter[token]))
            vector[vocab[token]] = tf_val * idf_val
    return vector

X_all = np.array([compute_tfidf(tokens, vocab, df_counter, doc_count) for tokens in tokenized_docs])
X_train = X_all[:len(X_train_raw)]
X_test = X_all[len(X_train_raw):]

# ✅ Manual Logistic Regression
def sigmoid(z):
    return 1 / (1 + np.exp(-z))

def train_logistic_regression(X, y, lr=0.1, epochs=1000):
    X = np.insert(X, 0, 1, axis=1)
    weights = np.zeros(X.shape[1])
    for _ in range(epochs):
        z = np.dot(X, weights)
        h = sigmoid(z)
        gradient = np.dot(X.T, (h - y)) / y.size
        weights -= lr * gradient
    return weights

def predict_logistic(X, weights):
    X = np.insert(X, 0, 1, axis=1)
    return (sigmoid(np.dot(X, weights)) >= 0.5).astype(int)

def predict_proba_logistic(X, weights):
    X = np.insert(X, 0, 1, axis=1)
    return sigmoid(np.dot(X, weights))

# ✅ Train and Predict
weights = train_logistic_regression(X_train, y_train)
y_pred = predict_logistic(X_test, weights)
y_probs = predict_proba_logistic(X_test, weights)

# ✅ Manual Evaluation
def manual_metrics(y_true, y_pred):
    tp = sum((y_true == 1) & (y_pred == 1))
    tn = sum((y_true == 0) & (y_pred == 0))
    fp = sum((y_true == 0) & (y_pred == 1))
    fn = sum((y_true == 1) & (y_pred == 0))
    accuracy = (tp + tn) / len(y_true)
    precision = tp / (tp + fp) if (tp + fp) > 0 else 0
    recall = tp / (tp + fn) if (tp + fn) > 0 else 0
    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0
    print(f"\n🎯 Accuracy: {accuracy:.4f}")
    print(f"🧮 Confusion Matrix:\n[[TN: {tn}, FP: {fp}]\n [FN: {fn}, TP: {tp}]]")
    print(f"🧾 Class 1 → Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}")

manual_metrics(y_test, y_pred)

# ✅ Plot Confusion Matrix
import matplotlib.pyplot as plt
import seaborn as sns

cm = [[sum((y_test == 0) & (y_pred == 0)), sum((y_test == 0) & (y_pred == 1))],
      [sum((y_test == 1) & (y_pred == 0)), sum((y_test == 1) & (y_pred == 1))]]

plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", cbar=False,
            xticklabels=["Pred 0", "Pred 1"], yticklabels=["Actual 0", "Actual 1"])
plt.title("Confusion Matrix (Manual Logistic Regression)")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.show()

# ✅ Fully Manual ML Pipeline with Manual Stacking (KNN + Logistic Regression)
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import re
from collections import defaultdict, Counter
import math

# ✅ Set seed
np.random.seed(42)

# ✅ Load dataset
# (Make sure 'merge-csv.com__683fc98d75a00.csv' is present in your working directory)
df = pd.read_csv("merge-csv.com__683fc98d75a00.csv", names=["id", "sequence", "label"], skiprows=1)

# ✅ Clean dataset manually
df.dropna(subset=["sequence", "label"], inplace=True)
df["label"] = pd.to_numeric(df["label"], errors='coerce')
df.dropna(subset=["label"], inplace=True)
df["label"] = df["label"].astype(int)
df = df[df["sequence"].apply(lambda x: bool(re.fullmatch(r"[acgt]+", x.lower())))]
df["sequence"] = df["sequence"].str.lower()
df = df[df["sequence"].apply(lambda x: len(x) >= 6)]

# ✅ Generate 6-mers
def get_kmers(seq, k=6):
    return " ".join([seq[i:i+k] for i in range(len(seq) - k + 1)])
df["kmers"] = df["sequence"].apply(get_kmers)

# ✅ Balance dataset manually
df_major = df[df["label"] == 0]
df_minor = df[df["label"] == 1]
df_minor_upsampled = df_minor.sample(n=len(df_major), replace=True, random_state=42)
df_balanced = pd.concat([df_major, df_minor_upsampled]).sample(frac=1, random_state=42).reset_index(drop=True)
df_balanced = df_balanced.iloc[:20000]  # subsample to 20000 rows

# ✅ Manual train-test split
split_index = int(len(df_balanced) * 0.8)
X = df_balanced["kmers"].values
y = df_balanced["label"].values
X_train_raw, X_test_raw = X[:split_index], X[split_index:]
y_train, y_test = y[:split_index], y[split_index:]

# ✅ Manual TF-IDF
def extract_kmers(seq, ks=(5, 6)):
    tokens = []
    for k in ks:
        tokens.extend([seq[i:i+k] for i in range(len(seq) - k + 1)])
    return tokens

all_docs = list(X_train_raw) + list(X_test_raw)
tokenized_docs = [extract_kmers(seq) for seq in all_docs]
doc_count = len(tokenized_docs)
df_counter = defaultdict(int)
for tokens in tokenized_docs:
    for token in set(tokens):
        df_counter[token] += 1

# Top 2000 tokens
top_kmers = sorted(df_counter.items(), key=lambda x: -x[1])[:2000]
vocab = {token: idx for idx, (token, _) in enumerate(top_kmers)}

def compute_tfidf(tokens, vocab, df_counter, N):
    tf = Counter(tokens)
    vector = np.zeros(len(vocab))
    for token, count in tf.items():
        if token in vocab:
            tf_val = count
            idf_val = math.log(N / (1 + df_counter[token]))
            vector[vocab[token]] = tf_val * idf_val
    return vector

X_all = np.array([compute_tfidf(tokens, vocab, df_counter, doc_count) for tokens in tokenized_docs])
X_train = X_all[:len(X_train_raw)]
X_test = X_all[len(X_train_raw):]

# ✅ Manual Logistic Regression
def sigmoid(z):
    return 1 / (1 + np.exp(-z))

def train_logistic_regression(X, y, lr=0.1, epochs=1000):
    X = np.insert(X, 0, 1, axis=1)
    weights = np.zeros(X.shape[1])
    for _ in range(epochs):
        z = np.dot(X, weights)
        h = sigmoid(z)
        gradient = np.dot(X.T, (h - y)) / y.size
        weights -= lr * gradient
    return weights

def predict_logistic(X, weights):
    X = np.insert(X, 0, 1, axis=1)
    return (sigmoid(np.dot(X, weights)) >= 0.5).astype(int)

def predict_proba_logistic(X, weights):
    X = np.insert(X, 0, 1, axis=1)
    return sigmoid(np.dot(X, weights))

# ✅ Manual KNN
def knn_predict(X_train, y_train, X_test, k=5):
    predictions = []
    for test_vec in X_test:
        distances = [np.linalg.norm(test_vec - train_vec) for train_vec in X_train]
        top_k_indices = np.argsort(distances)[:k]
        top_k_labels = y_train[top_k_indices]
        pred = Counter(top_k_labels).most_common(1)[0][0]
        predictions.append(pred)
    return np.array(predictions)

# ✅ Train both base models
log_weights = train_logistic_regression(X_train, y_train)
log_pred = predict_logistic(X_test, log_weights)
knn_pred = knn_predict(X_train, y_train, X_test, k=5)

# ✅ Manual stacking (majority voting)
def majority_vote(pred1, pred2):
    return np.array([Counter([p1, p2]).most_common(1)[0][0] for p1, p2 in zip(pred1, pred2)])

ensemble_pred = majority_vote(log_pred, knn_pred)

# ✅ Manual Evaluation
def manual_metrics(y_true, y_pred):
    tp = sum((y_true == 1) & (y_pred == 1))
    tn = sum((y_true == 0) & (y_pred == 0))
    fp = sum((y_true == 0) & (y_pred == 1))
    fn = sum((y_true == 1) & (y_pred == 0))
    accuracy = (tp + tn) / len(y_true)
    precision = tp / (tp + fp) if (tp + fp) > 0 else 0
    recall = tp / (tp + fn) if (tp + fn) > 0 else 0
    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0
    print(f"\n🎯 Accuracy: {accuracy:.4f}")
    print(f"🧮 Confusion Matrix:\n[[TN: {tn}, FP: {fp}]\n [FN: {fn}, TP: {tp}]]")
    print(f"🧾 Class 1 → Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}")

manual_metrics(y_test, ensemble_pred)

# ✅ Plot Confusion Matrix
cm = [[sum((y_test == 0) & (ensemble_pred == 0)), sum((y_test == 0) & (ensemble_pred == 1))],
      [sum((y_test == 1) & (ensemble_pred == 0)), sum((y_test == 1) & (ensemble_pred == 1))]]

plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", cbar=False,
            xticklabels=["Pred 0", "Pred 1"], yticklabels=["Actual 0", "Actual 1"])
plt.title("Confusion Matrix (Manual Ensemble)")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.show()

# ✅ Fully Manual Stacking Classifier: Logistic Regression + KNN + Manual Random Forest
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import re
from collections import defaultdict, Counter
import math

np.random.seed(42)

# ✅ Load and clean data
df = pd.read_csv("merge-csv.com__683fc98d75a00.csv", names=["id", "sequence", "label"], skiprows=1)
df.dropna(subset=["sequence", "label"], inplace=True)
df["label"] = pd.to_numeric(df["label"], errors='coerce')
df.dropna(subset=["label"], inplace=True)
df["label"] = df["label"].astype(int)
df = df[df["sequence"].apply(lambda x: bool(re.fullmatch(r"[acgt]+", x.lower())))]
df["sequence"] = df["sequence"].str.lower()
df = df[df["sequence"].apply(lambda x: len(x) >= 6)]

def get_kmers(seq, k=6):
    return " ".join([seq[i:i+k] for i in range(len(seq) - k + 1)])
df["kmers"] = df["sequence"].apply(get_kmers)

# ✅ Balance dataset
major = df[df.label == 0]
minor = df[df.label == 1].sample(n=len(major), replace=True, random_state=42)
df_bal = pd.concat([major, minor]).sample(frac=1, random_state=42).reset_index(drop=True)[:20000]

# ✅ Train-test split
split = int(0.8 * len(df_bal))
X_raw = df_bal["kmers"].values
y = df_bal["label"].values
X_train_raw, X_test_raw = X_raw[:split], X_raw[split:]
y_train, y_test = y[:split], y[split:]

# ✅ Manual TF-IDF

def extract_kmers(seq, ks=(5, 6)):
    return [seq[i:i+k] for k in ks for i in range(len(seq)-k+1)]

tokenized_docs = [extract_kmers(seq) for seq in X_raw]
df_counter = defaultdict(int)
for doc in tokenized_docs:
    for token in set(doc):
        df_counter[token] += 1

vocab = {kmer: i for i, (kmer, _) in enumerate(sorted(df_counter.items(), key=lambda x: -x[1])[:2000])}

def compute_tfidf(tokens, vocab, df_count, N):
    tf = Counter(tokens)
    vec = np.zeros(len(vocab))
    for token, cnt in tf.items():
        if token in vocab:
            idf = math.log(N / (1 + df_count[token]))
            vec[vocab[token]] = cnt * idf
    return vec

N = len(tokenized_docs)
X_all = np.array([compute_tfidf(doc, vocab, df_counter, N) for doc in tokenized_docs])
X_train, X_test = X_all[:split], X_all[split:]

# ✅ Manual Logistic Regression

def sigmoid(z): return 1 / (1 + np.exp(-z))

def train_logistic(X, y, lr=0.1, epochs=1000):
    X = np.insert(X, 0, 1, axis=1)
    w = np.zeros(X.shape[1])
    for _ in range(epochs):
        z = np.dot(X, w)
        h = sigmoid(z)
        grad = np.dot(X.T, (h - y)) / y.size
        w -= lr * grad
    return w

def predict_logistic(X, w):
    X = np.insert(X, 0, 1, axis=1)
    return (sigmoid(np.dot(X, w)) >= 0.5).astype(int)

def predict_proba_logistic(X, w):
    X = np.insert(X, 0, 1, axis=1)
    return sigmoid(np.dot(X, w))

# ✅ Manual KNN

def knn_predict(X_train, y_train, X_test, k=5):
    pred = []
    for x in X_test:
        dist = [np.linalg.norm(x - t) for t in X_train]
        idx = np.argsort(dist)[:k]
        labels = y_train[idx]
        pred.append(Counter(labels).most_common(1)[0][0])
    return np.array(pred)

# ✅ Manual Decision Tree & Random Forest
class Node:
    def __init__(self, feat=None, thresh=None, left=None, right=None, value=None):
        self.feat = feat
        self.thresh = thresh
        self.left = left
        self.right = right
        self.value = value
    def is_leaf(self): return self.value is not None

class ManualTree:
    def __init__(self, max_depth=5): self.max_depth = max_depth

    def fit(self, X, y): self.root = self._grow(X, y)

    def _grow(self, X, y, d=0):
        if d >= self.max_depth or len(set(y)) == 1:
            return Node(value=Counter(y).most_common(1)[0][0])
        m, n = X.shape
        best_gain, feat, thresh = -1, None, None
        for i in range(n):
            vals = np.unique(X[:, i])
            for t in vals:
                left, right = y[X[:, i] <= t], y[X[:, i] > t]
                if len(left) == 0 or len(right) == 0: continue
                gain = self._gini_gain(y, left, right)
                if gain > best_gain:
                    best_gain, feat, thresh = gain, i, t
        if feat is None:
            return Node(value=Counter(y).most_common(1)[0][0])
        left_idx = X[:, feat] <= thresh
        right_idx = ~left_idx
        return Node(feat, thresh,
                    self._grow(X[left_idx], y[left_idx], d+1),
                    self._grow(X[right_idx], y[right_idx], d+1))

    def _gini_gain(self, y, l, r):
        g = lambda y: 1 - sum((np.sum(y == c)/len(y))**2 for c in np.unique(y))
        return g(y) - (len(l)/len(y))*g(l) - (len(r)/len(y))*g(r)

    def predict(self, X):
        return np.array([self._traverse(x, self.root) for x in X])

    def _traverse(self, x, node):
        if node.is_leaf(): return node.value
        if x[node.feat] <= node.thresh:
            return self._traverse(x, node.left)
        else:
            return self._traverse(x, node.right)

class ManualForest:
    def __init__(self, n_trees=5, max_depth=5):
        self.n_trees = n_trees
        self.max_depth = max_depth

    def fit(self, X, y):
        self.trees = []
        for _ in range(self.n_trees):
            idx = np.random.choice(len(X), len(X), replace=True)
            tree = ManualTree(self.max_depth)
            tree.fit(X[idx], y[idx])
            self.trees.append(tree)

    def predict(self, X):
        preds = np.array([tree.predict(X) for tree in self.trees])
        return np.array([Counter(row).most_common(1)[0][0] for row in preds.T])

# ✅ Train base models
log_w = train_logistic(X_train, y_train)
log_train_prob = predict_proba_logistic(X_train, log_w)
knn_train_pred = knn_predict(X_train, y_train, X_train)
rf = ManualForest(n_trees=5, max_depth=5)
rf.fit(X_train, y_train)
rf_train_pred = rf.predict(X_train)

meta_X_train = np.column_stack([log_train_prob, knn_train_pred, rf_train_pred])
meta_w = train_logistic(meta_X_train, y_train)

# ✅ Test-time base predictions
log_test_prob = predict_proba_logistic(X_test, log_w)
knn_test_pred = knn_predict(X_train, y_train, X_test)
rf_test_pred = rf.predict(X_test)

meta_X_test = np.column_stack([log_test_prob, knn_test_pred, rf_test_pred])
y_pred = predict_logistic(meta_X_test, meta_w)

# ✅ Evaluation
def metrics(y_true, y_pred):
    tp = np.sum((y_true == 1) & (y_pred == 1))
    tn = np.sum((y_true == 0) & (y_pred == 0))
    fp = np.sum((y_true == 0) & (y_pred == 1))
    fn = np.sum((y_true == 1) & (y_pred == 0))
    acc = (tp + tn) / len(y_true)
    prec = tp / (tp + fp) if (tp + fp) else 0
    rec = tp / (tp + fn) if (tp + fn) else 0
    f1 = 2 * prec * rec / (prec + rec) if (prec + rec) else 0
    print(f"\n🎯 Accuracy: {acc:.4f}\n🧾 Precision: {prec:.4f}, Recall: {rec:.4f}, F1: {f1:.4f}")
    print(f"🧮 Confusion Matrix:\n[[TN: {tn}, FP: {fp}]\n [FN: {fn}, TP: {tp}]]")

metrics(y_test, y_pred)

# ✅ Plot
plt.figure(figsize=(6,5))
sns.heatmap([[np.sum((y_test==0)&(y_pred==0)), np.sum((y_test==0)&(y_pred==1))],
             [np.sum((y_test==1)&(y_pred==0)), np.sum((y_test==1)&(y_pred==1))]],
             annot=True, fmt="d", cmap="Blues", cbar=False,
             xticklabels=["Pred 0", "Pred 1"], yticklabels=["Actual 0", "Actual 1"])
plt.title("Manual Stacking Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.show()

# ✅ Fully Manual Stacking Classifier (Improved for 99% Accuracy)
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import re
from collections import defaultdict, Counter
import math

np.random.seed(42)

# ✅ Load and clean data
df = pd.read_csv("merge-csv.com__683fc98d75a00.csv", names=["id", "sequence", "label"], skiprows=1)
df.dropna(subset=["sequence", "label"], inplace=True)
df["label"] = pd.to_numeric(df["label"], errors='coerce')
df.dropna(subset=["label"], inplace=True)
df["label"] = df["label"].astype(int)
df = df[df["sequence"].apply(lambda x: bool(re.fullmatch(r"[acgt]+", x.lower())))]
df["sequence"] = df["sequence"].str.lower()
df = df[df["sequence"].apply(lambda x: len(x) >= 6)]

def get_kmers(seq, k=6):
    return " ".join([seq[i:i+k] for i in range(len(seq) - k + 1)])
df["kmers"] = df["sequence"].apply(get_kmers)

# ✅ Balance dataset
major = df[df.label == 0]
minor = df[df.label == 1].sample(n=len(major), replace=True, random_state=42)
df_bal = pd.concat([major, minor]).sample(frac=1, random_state=42).reset_index(drop=True)[:20000]

# ✅ Train-test split
split = int(0.8 * len(df_bal))
X_raw = df_bal["kmers"].values
y = df_bal["label"].values
X_train_raw, X_test_raw = X_raw[:split], X_raw[split:]
y_train, y_test = y[:split], y[split:]

# ✅ Manual TF-IDF

def extract_kmers(seq, ks=(5, 6, 7)):
    return [seq[i:i+k] for k in ks for i in range(len(seq)-k+1)]

tokenized_docs = [extract_kmers(seq) for seq in X_raw]
df_counter = defaultdict(int)
for doc in tokenized_docs:
    for token in set(doc):
        df_counter[token] += 1

vocab = {kmer: i for i, (kmer, _) in enumerate(sorted(df_counter.items(), key=lambda x: -x[1])[:3000])}

def compute_tfidf(tokens, vocab, df_count, N):
    tf = Counter(tokens)
    vec = np.zeros(len(vocab))
    for token, cnt in tf.items():
        if token in vocab:
            idf = math.log((N + 1) / (1 + df_count[token])) + 1
            vec[vocab[token]] = (1 + math.log(cnt)) * idf
    norm = np.linalg.norm(vec)
    return vec / norm if norm != 0 else vec

N = len(tokenized_docs)
X_all = np.array([compute_tfidf(doc, vocab, df_counter, N) for doc in tokenized_docs])
X_train, X_test = X_all[:split], X_all[split:]

# ✅ Manual Logistic Regression

def sigmoid(z): return 1 / (1 + np.exp(-z))

def train_logistic(X, y, lr=0.05, epochs=2000):
    X = np.insert(X, 0, 1, axis=1)
    w = np.zeros(X.shape[1])
    for _ in range(epochs):
        z = np.dot(X, w)
        h = sigmoid(z)
        grad = np.dot(X.T, (h - y)) / y.size
        w -= lr * grad
    return w

def predict_logistic(X, w):
    X = np.insert(X, 0, 1, axis=1)
    return (sigmoid(np.dot(X, w)) >= 0.5).astype(int)

def predict_proba_logistic(X, w):
    X = np.insert(X, 0, 1, axis=1)
    return sigmoid(np.dot(X, w))

# ✅ Manual KNN (cosine distance)
def cosine_dist(a, b):
    return 1 - np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b) + 1e-8)

def knn_predict(X_train, y_train, X_test, k=3):
    pred = []
    for x in X_test:
        dist = [cosine_dist(x, t) for t in X_train]
        idx = np.argsort(dist)[:k]
        labels = y_train[idx]
        pred.append(Counter(labels).most_common(1)[0][0])
    return np.array(pred)

# ✅ Manual Random Forest
class Node:
    def __init__(self, feat=None, thresh=None, left=None, right=None, value=None):
        self.feat = feat
        self.thresh = thresh
        self.left = left
        self.right = right
        self.value = value
    def is_leaf(self): return self.value is not None

class ManualTree:
    def __init__(self, max_depth=15): self.max_depth = max_depth

    def fit(self, X, y): self.root = self._grow(X, y)

    def _grow(self, X, y, d=0):
        if d >= self.max_depth or len(set(y)) == 1:
            return Node(value=Counter(y).most_common(1)[0][0])
        m, n = X.shape
        best_gain, feat, thresh = -1, None, None
        for i in range(n):
            vals = np.unique(X[:, i])
            for t in vals:
                left, right = y[X[:, i] <= t], y[X[:, i] > t]
                if len(left) == 0 or len(right) == 0: continue
                gain = self._gini_gain(y, left, right)
                if gain > best_gain:
                    best_gain, feat, thresh = gain, i, t
        if feat is None:
            return Node(value=Counter(y).most_common(1)[0][0])
        left_idx = X[:, feat] <= thresh
        right_idx = ~left_idx
        return Node(feat, thresh,
                    self._grow(X[left_idx], y[left_idx], d+1),
                    self._grow(X[right_idx], y[right_idx], d+1))

    def _gini_gain(self, y, l, r):
        g = lambda y: 1 - sum((np.sum(y == c)/len(y))**2 for c in np.unique(y))
        return g(y) - (len(l)/len(y))*g(l) - (len(r)/len(y))*g(r)

    def predict(self, X):
        return np.array([self._traverse(x, self.root) for x in X])

    def _traverse(self, x, node):
        if node.is_leaf(): return node.value
        return self._traverse(x, node.left) if x[node.feat] <= node.thresh else self._traverse(x, node.right)

class ManualForest:
    def __init__(self, n_trees=25, max_depth=15):
        self.n_trees = n_trees
        self.max_depth = max_depth

    def fit(self, X, y):
        self.trees = []
        for _ in range(self.n_trees):
            idx = np.random.choice(len(X), len(X), replace=True)
            tree = ManualTree(self.max_depth)
            tree.fit(X[idx], y[idx])
            self.trees.append(tree)

    def predict(self, X):
        preds = np.array([tree.predict(X) for tree in self.trees])
        return np.array([Counter(row).most_common(1)[0][0] for row in preds.T])

# ✅ Train base models
log_w = train_logistic(X_train, y_train)
log_train_prob = predict_proba_logistic(X_train, log_w)
knn_train_pred = knn_predict(X_train, y_train, X_train, k=3)
rf = ManualForest(n_trees=25, max_depth=15)
rf.fit(X_train, y_train)
rf_train_pred = rf.predict(X_train)

meta_X_train = np.column_stack([log_train_prob, knn_train_pred, rf_train_pred])
meta_w = train_logistic(meta_X_train, y_train)

# ✅ Test predictions
log_test_prob = predict_proba_logistic(X_test, log_w)
knn_test_pred = knn_predict(X_train, y_train, X_test, k=3)
rf_test_pred = rf.predict(X_test)

meta_X_test = np.column_stack([log_test_prob, knn_test_pred, rf_test_pred])
y_pred = predict_logistic(meta_X_test, meta_w)

# ✅ Evaluation
def metrics(y_true, y_pred):
    tp = np.sum((y_true == 1) & (y_pred == 1))
    tn = np.sum((y_true == 0) & (y_pred == 0))
    fp = np.sum((y_true == 0) & (y_pred == 1))
    fn = np.sum((y_true == 1) & (y_pred == 0))
    acc = (tp + tn) / len(y_true)
    prec = tp / (tp + fp) if (tp + fp) else 0
    rec = tp / (tp + fn) if (tp + fn) else 0
    f1 = 2 * prec * rec / (prec + rec) if (prec + rec) else 0
    print(f"\n🎯 Accuracy: {acc:.4f}\n🧾 Precision: {prec:.4f}, Recall: {rec:.4f}, F1: {f1:.4f}")
    print(f"🧮 Confusion Matrix:\n[[TN: {tn}, FP: {fp}]\n [FN: {fn}, TP: {tp}]]")

metrics(y_test, y_pred)

# ✅ Plot Confusion Matrix
plt.figure(figsize=(6,5))
sns.heatmap([[np.sum((y_test==0)&(y_pred==0)), np.sum((y_test==0)&(y_pred==1))],
             [np.sum((y_test==1)&(y_pred==0)), np.sum((y_test==1)&(y_pred==1))]],
             annot=True, fmt="d", cmap="Blues", cbar=False,
             xticklabels=["Pred 0", "Pred 1"], yticklabels=["Actual 0", "Actual 1"])
plt.title("Manual Stacking Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.show()